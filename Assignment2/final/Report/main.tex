%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% fphw Assignment
% LaTeX Template
% Version 1.0 (27/04/2019)
%
% This template originates from:
% https://www.LaTeXTemplates.com
%
% Authors:
% Class by Felipe Portales-Oliva (f.portales.oliva@gmail.com) with template 
% content and modifications by Vel (vel@LaTeXTemplates.com)
%
% Template (this file) License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[
	12pt, % Default font size, values between 10pt-12pt are allowed
	%letterpaper, % Uncomment for US letter paper size
	%spanish, % Uncomment for Spanish
]{fphw}

% Template-specific packages
\usepackage[utf8]{inputenc} % Required for inputting international characters
\usepackage[T1]{fontenc} % Output font encoding for international characters
\usepackage{multicol, latexsym, amsmath, amssymb}
\usepackage{blindtext}
\usepackage{subcaption}
\usepackage{caption}
\usepackage{wrapfig}
\usepackage{tabu}
\usepackage[dvipsnames]{xcolor}
\usepackage{floatflt}

\usepackage{graphicx} % Required for including images

\usepackage{booktabs} % Required for better horizontal rules in tables

\usepackage{listings} % Required for insertion of code

\usepackage{enumerate} % To modify the enumerate environment


%----------------------------------------------------------------------------------------
%	ASSIGNMENT INFORMATION
%----------------------------------------------------------------------------------------

\title{Assignment 2} % Assignment title

\author{Giuliano Martinelli 1915652, Gabriele Giannotta 1909375, Mario Dhimitri 1910181 } % Student name

\date{November 19th, 2020} % Due date

\institute{Sapienza Universit√† di Roma \\ Data Science} % Institute 

\class{Advanced Machine Learning} % Course or class name

\professor{Fabio Galasso} % Professor 

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Output the assignment title, created automatically using the information in the custom commands above

%----------------------------------------------------------------------------------------
%	ASSIGNMENT CONTENT
%----------------------------------------------------------------------------------------

\section*{Question 2 - Backpropagation}
\section* {2. a}

Verify that the loss function defined in Eq. (1) has gradient w.r.t. $z^{(3)}$ as Eq. (2):

\begin{equation}
\begin{gathered}
$$
J\left(\theta,\left\{x_{i}, y_{i}\right\}_{i=1}^{N}\right)=\frac{1}{N} \sum_{i=1}^{N}-\log \left[\frac{\exp \left(z_{i}^{(3)}\right)_{y_{i}}}{\sum_{j=1}^{K} \exp \left(z_{i}^{(3)}\right)_{j}}\right]
$$
\end{gathered}
\end{equation}
\\
\begin{equation}
\begin{gathered}
$$
\frac{\partial J}{\partial z_{i}^{(3)}}\left(\theta,\left\{x_{i}, y_{i}\right\}_{i=1}^{N}\right)=\frac{1}{N}\left(\psi\left(z_{i}^{(3)}\right)-\delta_{i y_{i}}\right)
$$
\end{gathered}
\end{equation}
\\
Where $\delta$ is the Kronecker delta:

$$
\delta_{i j}=\left\{\begin{array}{ll}
1, & \text { if } i=j \\
0, & \text { otherwise }
\end{array}\right.
$$
\\
It is possible to verify the initial assumption by calculating the gradient:

\begin{enumerate}
\item $f(x) = \frac{1}{N} log(x) \rightarrow \frac{\partial f(x)}{\partial x} = -\frac{1}{Nx}$  \\ 

$J\left(\theta,\left\{x_{i}, y_{i}\right\}_{i=1}^{N}\right) = f(x) = - \frac {1}{N} log(\psi (z_{i}^{(3)})_{y_{i}}),\ \ \ \ \ \  x = \psi(z_{i}^{(3)})_{y_{i}} $ \\ 

$\frac{\partial J}{\partial \psi(z_{i}^{(3)})_{y_{i}}} = - \frac{1}{N \psi(z_{i}^{(3)})_{y_{i}}} = \frac{\partial J}{\partial a_{i}^{(3)}}$ \\


\item $f(x) = \psi(x) \rightarrow \frac{\partial f(x)}{\partial x} = \psi (x) (1 - \psi(x))$ \\

$ a_{i}^{(3)} = f(x) = \psi(z_{i}^{(3)}),\ \ \ \ \ \ x = z_{y_{i}}^{(3)}$ \\

$ \frac{\partial a_{i}^{(3)}}{\partial z_j} = \psi(z_{i}^{(3)})_{y_{i}} (1 - \psi(z_{i}^{(3)})_{y_{i}}) $ \\

\item $\frac{\partial J}{\partial z_{i}^{(3)}} = \frac{\partial J}{\partial a_{i}^{(3)}} \frac{\partial a_{i}^{(3)}}{\partial z_{i}^{(3)}} = 1 (1 - \psi(z_{i}^{(3)})_{y_{i}}) = \frac{1}{N} (\psi(z_{i}^{(3)})_{y_{i}} - 1)$ \\

This because $\frac{\partial J}{\partial a_{i}^{(3)}}$ is the upstream gradient.

\end{enumerate}

\newpage
\section* {2. b}



To verify that the partial derivative of the loss w.r.t. $W^{(2)}$ is:

$$
\begin{aligned}
\frac{\partial J}{\partial W^{(2)}}\left(\theta,\left\{x_{i}, y_{i}\right\}_{i=1}^{N}\right)=& \sum_{i=1}^{N} \frac{\partial J}{\partial z_{i}^{(3)}} \cdot \frac{\partial z_{i}^{(3)}}{\partial W^{(2)}} \\
&=\sum_{i=1}^{N} \frac{1}{N}\left(\psi\left(z_{i}^{(3)}\right)-\delta_{i y_{i}}\right) a_{i}^{(2)^{T}}
\end{aligned}
$$

We can use the property as follows, that is:\\ 


$f(x) = aW, \ \ \ \ \ \ \frac{\partial f(x)}{\partial a} = W,\ \ \ \ \ \ \frac{\partial f(x)}{\partial W} = a$\\

Using upstream and local gradient:\\

$\frac{\partial J}{\partial W_2} = \frac{\partial J}{\partial z_{i}^{(3)}} \frac{\partial z_{i}^{(3)}}{\partial W_2} \ \ \ \ \ \ \ \ \ \frac{\partial z_{i}^{(3)}}{\partial W_2} = a_{i}^{(2)} \ \ \ \ \ \ since \ \  z_{i}^{(3)} = W_2 a_{i}^{(2)} + b $\\ \\

$\frac{\partial J}{\partial W_2} = \frac{1}{N} (\psi z_{i}^{(3)} - 1) a_{i}^{(2)}$\\

To verify that the regularized loss in Eq. (3) has the derivative as Eq. (4):


\begin{equation}
\begin{gathered}
$$
\tilde{J}\left(\theta,\left\{x_{i}, y_{i}\right\}_{i=1}^{N}\right)=\frac{1}{N} \sum_{i=1}^{N}-\log \left[\frac{\exp \left(z_{i}^{(3)}\right)_{y_{i}}}{\sum_{j=1}^{K} \exp \left(z_{i}^{(3)}\right)_{j}}\right]+\lambda\left(\left\|W^{(1)}\right\|_{2}^{2}+\left\|W^{(2)}\right\|_{2}^{2}\right)
$$
\end{gathered}
\end{equation}
\\
\begin{equation}
\begin{gathered}
$$
\frac{\partial \tilde{J}}{\partial W^{(2)}}=\sum_{i=1}^{N} \frac{1}{N}\left(\psi\left(z_{i}^{(3)}\right)-\delta_{i y_{i}}\right) a_{i}^{(2)^{T}}+2 \lambda W^{(2)}
$$
\end{gathered}
\end{equation}\ \\

We can do the following:\\ \\

$f(x) = \lambda\left(\left\|W^{(1)}\right\|_{2}^{2}+\left\|W^{(2)}\right\|_{2}^{2}\right) = \lambda\left(\left\|W^{(1)}\right\|_{2}^{2}\right) + \lambda\left(\left\|W^{(2)}\right\|_{2}^{2}\right) = $\\ \\

$\frac{f}{W_2} = 0 + \lambda \frac{\partial(\sum\sum(W_2)^2)}{\partial W_2} = 2\lambda W_2$\\ \\

$\frac{\partial J}{\partial W_2} = \frac{1}{N} (\psi(z_3) - 1) a_{2}^{T} + 2\lambda W_2$



















%------------------------------------------------
\end{document}
