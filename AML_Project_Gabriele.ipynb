{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy_of_AML_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UXG6e2PquoqN",
        "-_AXoIoMB0om",
        "XzkRmamqNDt_",
        "unyTDi0vbuRC"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c9bc797a0fdd49a3ad02dc007af6416c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8c7cb58ecb8c4e3480330781c272021b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1b5587a928ba4c089bf64d1c4032e344",
              "IPY_MODEL_0662d876f8e94430a5ad494f6d63f131"
            ]
          }
        },
        "8c7cb58ecb8c4e3480330781c272021b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b5587a928ba4c089bf64d1c4032e344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d3b57326ad3c404f824717d8cdf06956",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e4e53d87bb3b4f159edc059cad9f623d"
          }
        },
        "0662d876f8e94430a5ad494f6d63f131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_666f77c2e0e543928173fe81ea75104e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 136MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3275e7f1670345e2a0d74cf8f2879be1"
          }
        },
        "d3b57326ad3c404f824717d8cdf06956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e4e53d87bb3b4f159edc059cad9f623d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "666f77c2e0e543928173fe81ea75104e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3275e7f1670345e2a0d74cf8f2879be1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3673bc98d1eb4f0591ab742816753ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_872220fb58e248199f6cfbd0ec2528e8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e0f7ca50099040d9af935ffb0defbdf3",
              "IPY_MODEL_f84980212b924686b4a3850a9dcaa6d2"
            ]
          }
        },
        "872220fb58e248199f6cfbd0ec2528e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e0f7ca50099040d9af935ffb0defbdf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c114565d6775456787ba3cacef64bc7a",
            "_dom_classes": [],
            "description": "Epochs:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 8,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a661a6eb256d45a69a22afaa31959152"
          }
        },
        "f84980212b924686b4a3850a9dcaa6d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_12fd7ba5b1e7471ba851536015b8bd3f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/8 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b018e9c2746e4b298ee37f48920fbd78"
          }
        },
        "c114565d6775456787ba3cacef64bc7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a661a6eb256d45a69a22afaa31959152": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12fd7ba5b1e7471ba851536015b8bd3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b018e9c2746e4b298ee37f48920fbd78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d825373242d4b72918ab88bf3418729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9600e8aabae64b049ad2560904e7b556",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ffe73c5ce67e4b94ac1cae0f9c63e245",
              "IPY_MODEL_c2d13a6e10f4499e81a44a5a22af73b8"
            ]
          }
        },
        "9600e8aabae64b049ad2560904e7b556": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ffe73c5ce67e4b94ac1cae0f9c63e245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8cddc3bb7e06459fbcb4a0cec15aa206",
            "_dom_classes": [],
            "description": "Training:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 711,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eac8bcb556c24536953612f9fb573f54"
          }
        },
        "c2d13a6e10f4499e81a44a5a22af73b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_348fb179f8cf4f27980e7fa1d53d0b54",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/711 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_70934ba1c52c473db3381cee51fccd3e"
          }
        },
        "8cddc3bb7e06459fbcb4a0cec15aa206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eac8bcb556c24536953612f9fb573f54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "348fb179f8cf4f27980e7fa1d53d0b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "70934ba1c52c473db3381cee51fccd3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/g185/AMLrepository/blob/main/AML_Project_Gabriele.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXG6e2PquoqN"
      },
      "source": [
        "#***Download and unzip Dataset***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhlPBhD98p94"
      },
      "source": [
        "*   Create folders\n",
        "*   Download Recipe 5K + Annotations in drive\n",
        "*   Unzip files in folder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "KUrWflPRudbx",
        "outputId": "7c536d74-f3af-47a7-e08c-fdd65a533b31"
      },
      "source": [
        "#Create folders for models and datasets\n",
        "!mkdir \"/content/drive/My Drive/RecipeNet\" \n",
        "!mkdir \"/content/drive/My Drive/RecipeNet/datasets\" \n",
        "!mkdir \"/content/drive/My Drive/RecipeNet/datasets/download\" \n",
        "!mkdir \"/content/drive/My Drive/RecipeNet/datasets/extracted\" \n",
        "!mkdir \"/content/drive/My Drive/RecipeNet/datasets/preprocessed\" \n",
        "!mkdir \"/content/drive/My Drive/RecipeNet/model\" \n",
        "\n",
        "#Scarica dataset\n",
        "#Trascina i 3 zip\n",
        "\n",
        "#Unzip\n",
        "\"\"\"\n",
        "!unzip \"/content/drive/My Drive/RecipeNet/datasets/download/Recipes5k.zip\" -d \"/content/drive/My Drive/RecipeNet/datasets/extracted\"\n",
        "!unzip \"/content/drive/My Drive/RecipeNet/datasets/download/archive.zip\" -d \"/content/drive/My Drive/RecipeNet/datasets/extracted\"\n",
        "!unzip \"/content/drive/My Drive/RecipeNet/datasets/download/Ingredients101.zip\" -d \"/content/drive/My Drive/RecipeNet/datasets/extracted\"\n",
        "\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory â€˜/content/drive/My Drive/RecipeNetâ€™: File exists\n",
            "mkdir: cannot create directory â€˜/content/drive/My Drive/RecipeNet/datasetsâ€™: File exists\n",
            "mkdir: cannot create directory â€˜/content/drive/My Drive/RecipeNet/datasets/downloadâ€™: File exists\n",
            "mkdir: cannot create directory â€˜/content/drive/My Drive/RecipeNet/datasets/extractedâ€™: File exists\n",
            "mkdir: cannot create directory â€˜/content/drive/My Drive/RecipeNet/modelâ€™: File exists\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n!unzip \"/content/drive/My Drive/RecipeNet/datasets/download/Recipes5k.zip\" -d \"/content/drive/My Drive/RecipeNet/datasets/extracted\"\\n!unzip \"/content/drive/My Drive/RecipeNet/datasets/download/archive.zip\" -d \"/content/drive/My Drive/RecipeNet/datasets/extracted\"\\n!unzip \"/content/drive/My Drive/RecipeNet/datasets/download/Ingredients101.zip\" -d \"/content/drive/My Drive/RecipeNet/datasets/extracted\"\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT-TwMVuBLEv"
      },
      "source": [
        "#***Imports and Drive Mount***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOJPDp-bU6rr",
        "outputId": "5cdf78b4-7936-4770-be78-4da7ae4a4c17"
      },
      "source": [
        "#Imports\n",
        "import sys\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from tqdm import tqdm, tqdm_notebook, tnrange\n",
        "import sys\n",
        "import cv2\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from glob import glob\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "#Cuda\n",
        "device = torch.device(\"cuda\")\n",
        "torch.manual_seed(42) # try and make the results more reproducible\n",
        "print(torch.cuda.get_device_name(0))\n",
        "\n",
        "#Drive Mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla P100-PCIE-16GB\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_AXoIoMB0om"
      },
      "source": [
        "#***Project Parameters***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYIvhj8aB4NV"
      },
      "source": [
        "params = {}\n",
        "params[\"root\"] = \"/content/drive/My Drive/RecipeNet/\"\n",
        "params[\"images_dir\"] = params[\"root\"] + \"datasets/extracted/images/\" \n",
        "params[\"ingredients_per_class\"] = params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/ingredients_simplified.txt\" \n",
        "params[\"classes\"] = params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/classes.txt\" \n",
        "params[\"baseIngredients_dir\"] = params[\"root\"] + \"datasets/extracted/Ingredients101/ingredients_simplification/baseIngredients.txt\" \n",
        "params[\"epochs\"] = 8\n",
        "params[\"batch_size\"] = 64\n",
        "params[\"img_size\"] = (384,384)\n",
        "params[\"fast_training\"] = True\n",
        "params[\"freezed_layers\"] = 8"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzkRmamqNDt_"
      },
      "source": [
        "#***Data extraction and preprocessing***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5tPzq9WjV77"
      },
      "source": [
        "Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtUqblzXja33"
      },
      "source": [
        "#Ingredients x class\n",
        "f = open(params[\"ingredients_per_class\"], \"r\")\n",
        "ingredients = f.read().split('\\n')\n",
        "f.close()\n",
        "\n",
        "#Classes\n",
        "f = open(params[\"classes\"], \"r\")\n",
        "classes = f.read().split('\\n')\n",
        "f.close()\n",
        "\n",
        "#Ingredients\n",
        "f = open(params[\"baseIngredients_dir\"], \"r\")\n",
        "base_ing = f.read().split('\\n')\n",
        "base_ing = base_ing[0].split(\",\")\n",
        "f.close()\n",
        "\n",
        "#train images\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/train_images.txt\", \"r\")\n",
        "train_images = f.read().split('\\n')\n",
        "f.close()\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/train_labels.txt\", \"r\")\n",
        "train_labels = f.read().split('\\n')\n",
        "f.close()\n",
        "\n",
        "#validation images\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/val_images.txt\", \"r\")\n",
        "val_images = f.read().split('\\n')\n",
        "f.close()\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/val_labels.txt\", \"r\")\n",
        "val_labels = f.read().split('\\n')\n",
        "f.close()\n",
        "\n",
        "#test images\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/test_images.txt\", \"r\")\n",
        "test_images = f.read().split('\\n')\n",
        "f.close()\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/test_labels.txt\", \"r\")\n",
        "test_labels = f.read().split('\\n')\n",
        "f.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URPn4rnyjjoj"
      },
      "source": [
        "Dataframes Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOoX41Sdjm3A"
      },
      "source": [
        "#list of string in list of list of tokens\n",
        "new_ingredients = [arr.split(\",\") for arr in ingredients]\n",
        "\n",
        "#binary encode ingredients\n",
        "mlb = MultiLabelBinarizer()\n",
        "df = pd.DataFrame(mlb.fit_transform(new_ingredients),columns=mlb.classes_) \n",
        "df[\"target\"] = classes\n",
        "food_dict = df\n",
        "\n",
        "train_images = [params[\"images_dir\"] + s + \".jpg\" for s in train_images]\n",
        "all_img_df = pd.DataFrame({'path': train_images, 'class_id': train_labels})\n",
        "val_images = [params[\"images_dir\"] + s + \".jpg\" for s in val_images]\n",
        "val_img_df = pd.DataFrame({'path': val_images, 'class_id': val_labels})\n",
        "test_images = [params[\"images_dir\"] + s + \".jpg\" for s in test_images]\n",
        "test_img_df = pd.DataFrame({'path': test_images, 'class_id': test_labels})\n",
        "all_img_df = all_img_df[:-1]\n",
        "val_img_df = val_img_df[:-1]\n",
        "test_img_df = test_img_df[:-1]\n",
        "\n",
        "\n",
        "\n",
        "all_img_df['class_name'] = all_img_df['path'].map(lambda x: os.path.split(os.path.dirname(x))[-1])\n",
        "val_img_df['class_name'] = val_img_df['path'].map(lambda x: os.path.split(os.path.dirname(x))[-1])\n",
        "test_img_df['class_name'] = test_img_df['path'].map(lambda x: os.path.split(os.path.dirname(x))[-1])\n",
        "\n",
        "food_dict = food_dict.drop('', 1)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "468oZbcTjzjI"
      },
      "source": [
        "Train Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su9RKGPwj3M7",
        "outputId": "0cc43e87-8e33-4ad2-d7c3-695850b6093b"
      },
      "source": [
        "#Dataframe for train images\n",
        "new_data = []\n",
        "for index, row in all_img_df.iterrows():\n",
        "    #get binary encoding ingredients from lookup\n",
        "    food = row[\"class_name\"]\n",
        "    path = row[\"path\"]\n",
        "    class_id = row[\"class_id\"]\n",
        "    binary_encod = food_dict.loc[food_dict[\"target\"] == food]\n",
        "    binary_encod[\"path\"] = path\n",
        "    binary_encod[\"class_id\"] = class_id\n",
        "    #print(binary_encod)\n",
        "    #print((list(binary_encod.columns.values)))\n",
        "    #print(len(np.array(binary_encod)[0]))\n",
        "    new_data.append(np.array(binary_encod)[0])\n",
        "\n",
        "\n",
        "    \n",
        "col_names = list(binary_encod.columns.values)\n",
        "train_df = pd.DataFrame(new_data, columns = col_names)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTtejOUlj4l2"
      },
      "source": [
        "Validation Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE5pj15Ij75W",
        "outputId": "cf8e9320-f29e-4144-dc35-31a59de1aa31"
      },
      "source": [
        "val_data = []\n",
        "for index, row in val_img_df.iterrows():\n",
        "    #get binary encoding ingredients from lookup\n",
        "    food = row[\"class_name\"]\n",
        "    path = row[\"path\"]\n",
        "    class_id = row[\"class_id\"]\n",
        "    binary_encod = food_dict.loc[food_dict[\"target\"] == food]\n",
        "    binary_encod[\"path\"] = path\n",
        "    binary_encod[\"class_id\"] = int(class_id)\n",
        "    val_data.append(np.array(binary_encod)[0])\n",
        "val_df = pd.DataFrame(val_data, columns = col_names)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHK2_X4fj-l_"
      },
      "source": [
        "Test Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzdWTpbZeyap",
        "outputId": "a3b52d8f-6e4c-420d-e7bf-1773264cf86f"
      },
      "source": [
        "test_data = []\n",
        "for index, row in test_img_df.iterrows():\n",
        "    #get binary encoding ingredients from lookup\n",
        "    food = row[\"class_name\"]\n",
        "    path = row[\"path\"]\n",
        "    class_id = row[\"class_id\"]\n",
        "    binary_encod = food_dict.loc[food_dict[\"target\"] == food]\n",
        "    binary_encod[\"path\"] = path\n",
        "    binary_encod[\"class_id\"] = int(class_id)\n",
        "    test_data.append(np.array(binary_encod)[0])\n",
        "\n",
        "\n",
        "test_df = pd.DataFrame(test_data, columns = col_names)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unyTDi0vbuRC"
      },
      "source": [
        "#***DataGenerator***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CtfDNypczIt"
      },
      "source": [
        "class DataWrapper(data.Dataset):\n",
        "    ''' Data wrapper for pytorch's data loader function '''\n",
        "    def __init__(self, image_df, resize):\n",
        "        self.dataset = image_df\n",
        "        self.resize = resize\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        c_row = self.dataset.iloc[index]\n",
        "        target_arr = []\n",
        "        for item in c_row[targets].values:\n",
        "            target_arr.append(item)\n",
        "        #print(target_arr)\n",
        "        image_path, target = c_row['path'], torch.from_numpy(np.array(target_arr)).float()  #image and target\n",
        "        #read as rgb image, resize and convert to range 0 to 1\n",
        "        image = cv2.imread(image_path, 1)\n",
        "        if self.resize:\n",
        "            image = cv2.resize(image, params[\"img_size\"])/255.0 \n",
        "        else:\n",
        "            image = image/255.0\n",
        "        image = (torch.from_numpy(image.transpose(2,0,1))).float() #NxCxHxW\n",
        "        return image, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset.shape[0]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iZSnFTLNDim"
      },
      "source": [
        "#***Trasfer Learning Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "c9bc797a0fdd49a3ad02dc007af6416c",
            "8c7cb58ecb8c4e3480330781c272021b",
            "1b5587a928ba4c089bf64d1c4032e344",
            "0662d876f8e94430a5ad494f6d63f131",
            "d3b57326ad3c404f824717d8cdf06956",
            "e4e53d87bb3b4f159edc059cad9f623d",
            "666f77c2e0e543928173fe81ea75104e",
            "3275e7f1670345e2a0d74cf8f2879be1"
          ]
        },
        "id": "9bWUNYL4wdKR",
        "outputId": "dfab746d-d0d8-4c74-fff1-78f3fe2396d0"
      },
      "source": [
        "col_names = list(train_df.columns.values)\n",
        "targets = col_names[:-3]\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "output = len(targets)\n",
        "model.fc = nn.Linear(model.fc.in_features, output)\n",
        "\n",
        "layer = 0\n",
        "for name, child in model.named_children():\n",
        "    layer += 1\n",
        "    if layer < params[\"freezed_layers\"]:\n",
        "        for name2, param in child.named_parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9bc797a0fdd49a3ad02dc007af6416c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgnD-3N57df_",
        "outputId": "71b0dd35-411a-4076-8572-b3740aa1adaf"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=227, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsKbUajgwOzk"
      },
      "source": [
        "#***DCNN Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7emD5fKnhG9f"
      },
      "source": [
        "col_names = list(train_df.columns.values)\r\n",
        "targets = col_names[:-3]\r\n",
        "output = len(targets)\r\n",
        "\r\n",
        "class ConvNet(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(ConvNet, self).__init__()\r\n",
        "        self.layer1 = nn.Sequential(\r\n",
        "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2))\r\n",
        "        self.layer2 = nn.Sequential(\r\n",
        "            nn.Conv2d(64, 128, kernel_size=1, stride=1, padding=1),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\r\n",
        "        self.drop_out = nn.Dropout()\r\n",
        "        self.fc1 = nn.Linear(128, 1000)\r\n",
        "        self.fc2 = nn.Linear(1000, output)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "      out = self.layer1(x)\r\n",
        "      out = self.layer2(out)\r\n",
        "      out = out.reshape(out.size(0), -1)\r\n",
        "      out = self.drop_out(out)\r\n",
        "      out = self.fc1(out)\r\n",
        "      out = self.fc2(out)\r\n",
        "      return out"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-qv_YYS_O3a"
      },
      "source": [
        "model = ConvNet()\r\n",
        "\r\n",
        "# Loss and optimizer\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "rRtjhKGiIEfn",
        "outputId": "e7d6699e-6e63-4feb-bc43-6474424943d9"
      },
      "source": [
        "# Train the model\r\n",
        "total_step = len(train_loader)\r\n",
        "loss_list = []\r\n",
        "acc_list = []\r\n",
        "for epoch in range(2):\r\n",
        "    for i, (images, labels) in enumerate(train_loader):\r\n",
        "        # Run the forward pass\r\n",
        "        outputs = model(images)\r\n",
        "        loss = criterion(outputs, labels)\r\n",
        "        loss_list.append(loss.item())\r\n",
        "\r\n",
        "        # Backprop and perform Adam optimisation\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        # Track the accuracy\r\n",
        "        total = labels.size(0)\r\n",
        "        _, predicted = torch.max(outputs.data, 1)\r\n",
        "        correct = (predicted == labels).sum().item()\r\n",
        "        acc_list.append(correct / total)\r\n",
        "\r\n",
        "        if (i + 1) % 100 == 0:\r\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\r\n",
        "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\r\n",
        "                          (correct / total) * 100))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-0fa3f6ad2d03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Run the forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-0905f7695db3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x147456 and 64x294912)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgMUIGbwwtHO"
      },
      "source": [
        "#***Training***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tejkwYHPhx5o"
      },
      "source": [
        "Define Hamming Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1l7jgF4h83W"
      },
      "source": [
        "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
        "    '''\n",
        "    Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
        "    https://stackoverflow.com/q/32239577/395857\n",
        "    '''\n",
        "    acc_list = []\n",
        "    for i in range(y_true.shape[0]):\n",
        "        set_true = set( np.where(y_true[i])[0] )\n",
        "        set_pred = set( np.where(y_pred[i])[0] )\n",
        "        tmp_a = None\n",
        "        if len(set_true) == 0 and len(set_pred) == 0:\n",
        "            tmp_a = 1\n",
        "        else:\n",
        "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
        "                    float( len(set_true.union(set_pred)) )\n",
        "        acc_list.append(tmp_a)\n",
        "    return np.mean(acc_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5P5t3kOiWyN"
      },
      "source": [
        "Training Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAGn6B-hiZlR"
      },
      "source": [
        "if params[\"fast_training\"] == True:\n",
        "    train_df = train_df[:45450]\n",
        "    val_df = val_df[:5050]\n",
        "    test_df = test_df[:16830]\n",
        "            \n",
        "model = model.to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4BOAUZSif36"
      },
      "source": [
        "Dataset Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN34WEC3iiLB"
      },
      "source": [
        "train_dataset = DataWrapper(train_df, True)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,shuffle=True, batch_size=params[\"batch_size\"], pin_memory=False)\n",
        "\n",
        "val_dataset = DataWrapper(val_df, True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset,shuffle=True, batch_size=params[\"batch_size\"], pin_memory=False)\n",
        "\n",
        "test_dataset = DataWrapper(test_df, True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,shuffle=True, batch_size=params[\"batch_size\"], pin_memory=False)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCjVOOL4i48a"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "3673bc98d1eb4f0591ab742816753ef2",
            "872220fb58e248199f6cfbd0ec2528e8",
            "e0f7ca50099040d9af935ffb0defbdf3",
            "f84980212b924686b4a3850a9dcaa6d2",
            "c114565d6775456787ba3cacef64bc7a",
            "a661a6eb256d45a69a22afaa31959152",
            "12fd7ba5b1e7471ba851536015b8bd3f",
            "b018e9c2746e4b298ee37f48920fbd78",
            "8d825373242d4b72918ab88bf3418729",
            "9600e8aabae64b049ad2560904e7b556",
            "ffe73c5ce67e4b94ac1cae0f9c63e245",
            "c2d13a6e10f4499e81a44a5a22af73b8",
            "8cddc3bb7e06459fbcb4a0cec15aa206",
            "eac8bcb556c24536953612f9fb573f54",
            "348fb179f8cf4f27980e7fa1d53d0b54",
            "70934ba1c52c473db3381cee51fccd3e"
          ]
        },
        "id": "THX6oDqxqblX",
        "outputId": "67acca75-97d6-46ec-ae4a-7c20fce0b279"
      },
      "source": [
        "\n",
        "train_results = defaultdict(list)\n",
        "train_iter, test_iter, best_acc = 0,0,0\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize = (10, 10))\n",
        "ax1.set_title('Train Loss')\n",
        "ax2.set_title('Train Accuracy')\n",
        "ax3.set_title('Test Loss')\n",
        "ax4.set_title('Test Accuracy')\n",
        "\n",
        "f1_scores = defaultdict(list)\n",
        "for i in tnrange(params[\"epochs\"], desc='Epochs'):\n",
        "    print(\"Epoch \",i)\n",
        "    ## Train Phase\n",
        "    #Model switches to train phase\n",
        "    model.train() \n",
        "    \n",
        "    all_outputs = []\n",
        "    all_targets = []\n",
        "    # Running through all mini batches in the dataset\n",
        "    count, loss_val, correct, total = train_iter, 0, 0, 0\n",
        "    for img_data, target in tqdm_notebook(train_loader, desc='Training'):    \n",
        "        img_data, target = img_data.to(device), target.to(device)\n",
        "        \n",
        "        output = model(img_data) #FWD prop\n",
        "\n",
        "        loss = criterion(output, target) #Cross entropy loss\n",
        "        c_loss = loss.data.item()\n",
        "        ax1.plot(count, c_loss, 'r.')\n",
        "        loss_val += c_loss\n",
        "\n",
        "        optimizer.zero_grad() #Zero out any cached gradients\n",
        "        loss.backward() #Backward pass\n",
        "        optimizer.step() #Update the weights\n",
        "\n",
        "        total_batch = (target.size(0) * target.size(1))\n",
        "        total += total_batch\n",
        "        output_data = torch.sigmoid(output)>=0.5\n",
        "        target_data = (target==1.0)\n",
        "        for arr1,arr2 in zip(output_data, target_data):\n",
        "            all_outputs.append(list(arr1.cpu().numpy()))\n",
        "            all_targets.append(list(arr2.cpu().numpy()))\n",
        "        c_acc = torch.sum((output_data == target_data.to(device)).to(torch.float)).item()\n",
        "        ax2.plot(count, c_acc/total_batch, 'r.')\n",
        "        correct += c_acc\n",
        "        count +=1\n",
        "        \n",
        "    all_outputs = np.array(all_outputs)\n",
        "    all_targets = np.array(all_targets)\n",
        "    f1score_samples = f1_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    f1score_macro = f1_score(y_true=all_targets, y_pred=all_outputs, average='macro')\n",
        "    f1score_weighted = f1_score(y_true=all_targets, y_pred=all_outputs, average='weighted')\n",
        "    recall = recall_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    prec = precision_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    hamming = hamming_score(y_true=all_targets, y_pred=all_outputs)\n",
        "    \n",
        "    f1_scores[\"samples_train\"].append(f1score_samples)\n",
        "    f1_scores[\"macro_train\"].append(f1score_macro)\n",
        "    f1_scores[\"weighted_train\"].append(f1score_weighted)\n",
        "    f1_scores[\"hamming_train\"].append(hamming)\n",
        "    \n",
        "    train_loss_val, train_iter, train_acc = loss_val/len(train_loader.dataset), count, correct/float(total)\n",
        "    \n",
        "    print(\"Training loss: \", train_loss_val, \" train acc: \",train_acc)    \n",
        "    ## Test Phase\n",
        "    \n",
        "    #Model switches to test phase\n",
        "    model.eval()\n",
        "    \n",
        "    all_outputs = []\n",
        "    all_targets = []\n",
        "    #Running through all mini batches in the dataset\n",
        "    count, correct, total, lost_val = test_iter, 0, 0, 0\n",
        "    for img_data, target in tqdm_notebook(val_loader, desc='Testing'):\n",
        "        img_data, target = img_data.to(device), target.to(device)\n",
        "        output = model(img_data)\n",
        "        loss = criterion(output, target) #Cross entropy loss\n",
        "        c_loss = loss.data.item()\n",
        "        ax3.plot(count, c_loss, 'b.')\n",
        "        loss_val += c_loss\n",
        "        #Compute accuracy\n",
        "        #predicted = output.data.max(1)[1] #get index of max\n",
        "        total_batch = (target.size(0) * target.size(1))\n",
        "        total += total_batch\n",
        "        output_data = torch.sigmoid(output)>=0.5\n",
        "        target_data = (target==1.0)\n",
        "        #print(\"Predictions: \", output_data)\n",
        "        #print(\"Actual: \", target_data)\n",
        "        for arr1,arr2 in zip(output_data, target_data):\n",
        "            all_outputs.append(list(arr1.cpu().numpy()))\n",
        "            all_targets.append(list(arr2.cpu().numpy()))\n",
        "        c_acc = torch.sum((output_data == target_data.to(device)).to(torch.float)).item()\n",
        "        ax4.plot(count, c_acc/total_batch, 'b.')\n",
        "        correct += c_acc\n",
        "        count += 1\n",
        "    \n",
        "    #print(\"Outputs: \", len(all_outputs), \" x \", len(all_outputs[0]))\n",
        "    #print(\"Targets: \", len(all_targets), \" x \", len(all_targets[0]))\n",
        "    \n",
        "    #F1 Score\n",
        "    all_outputs = np.array(all_outputs)\n",
        "    all_targets = np.array(all_targets)\n",
        "    f1score_samples = f1_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    f1score_macro = f1_score(y_true=all_targets, y_pred=all_outputs, average='macro')\n",
        "    f1score_weighted = f1_score(y_true=all_targets, y_pred=all_outputs, average='weighted')\n",
        "    recall = recall_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    prec = precision_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    hamming = hamming_score(y_true=all_targets, y_pred=all_outputs)\n",
        "    \n",
        "    f1_scores[\"samples_test\"].append(f1score_samples)\n",
        "    f1_scores[\"macro_test\"].append(f1score_macro)\n",
        "    f1_scores[\"weighted_test\"].append(f1score_weighted)\n",
        "    f1_scores[\"hamming_test\"].append(hamming)\n",
        "    \n",
        "    #Accuracy over entire dataset\n",
        "    test_acc, test_iter, test_loss_val = correct/float(total), count, loss_val/len(test_loader.dataset)\n",
        "    print(\"Test set accuracy: \",test_acc)\n",
        "    print(\"f1_scores\", f1_scores)\n",
        "    train_results['epoch'].append(i)\n",
        "    train_results['train_loss'].append(train_loss_val)\n",
        "    train_results['train_acc'].append(train_acc)\n",
        "    train_results['train_iter'].append(train_iter)\n",
        "    \n",
        "    train_results['test_loss'].append(test_loss_val)\n",
        "    train_results['test_acc'].append(test_acc)\n",
        "    train_results['test_iter'].append(test_iter)\n",
        "    \n",
        "    #Save model with best accuracy\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        torch.save(model.state_dict(), 'best_model.pth') \n",
        "fig.savefig('train_curves.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3673bc98d1eb4f0591ab742816753ef2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epochs', max=8.0, style=ProgressStyle(description_width='â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d825373242d4b72918ab88bf3418729",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Training', max=711.0, style=ProgressStyle(description_widâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HgLjKiPkMLn"
      },
      "source": [
        "#***Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmFAVmC8kRFp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}