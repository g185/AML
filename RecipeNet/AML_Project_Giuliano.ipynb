{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy_of_AML_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UXG6e2PquoqN"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c544f374f94e4472adecc7149f7975dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c237c15807ab4caab405eebe0b448890",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ed8c16a200fb4298bd3f5b8b240b9fc6",
              "IPY_MODEL_8292618672b74f8ca276e1c8cd932dd9"
            ]
          }
        },
        "c237c15807ab4caab405eebe0b448890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed8c16a200fb4298bd3f5b8b240b9fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5a7abbb46ba24bce85211190ef19ec1a",
            "_dom_classes": [],
            "description": "Epochs:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 8,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_305764fc917d46a0901679d203f82918"
          }
        },
        "8292618672b74f8ca276e1c8cd932dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ebbabb96001941fdb747aa15a6e70a1f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/8 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb77e4a8f0fa434f825caad2c9927155"
          }
        },
        "5a7abbb46ba24bce85211190ef19ec1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "305764fc917d46a0901679d203f82918": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ebbabb96001941fdb747aa15a6e70a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb77e4a8f0fa434f825caad2c9927155": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3d40bc28f7745dc8e09761f25442deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ef002da610304eea9201faa6f8da9eed",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_36184149091e45f9b416d4c757371927",
              "IPY_MODEL_d4e906d01a884c9bad6b3b31997fef50"
            ]
          }
        },
        "ef002da610304eea9201faa6f8da9eed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36184149091e45f9b416d4c757371927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1deee7e1bb9c4bd799cc2f33dd51bcf5",
            "_dom_classes": [],
            "description": "Training:  16%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 213,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 34,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_254ccfa0c5df40818f8a777985a8cf05"
          }
        },
        "d4e906d01a884c9bad6b3b31997fef50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_57abc6db510343588a9da876702fc71a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 34/213 [06:55&lt;34:33, 11.58s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_59827b894fc94ef3a7e42456d1dc3be7"
          }
        },
        "1deee7e1bb9c4bd799cc2f33dd51bcf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "254ccfa0c5df40818f8a777985a8cf05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "57abc6db510343588a9da876702fc71a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "59827b894fc94ef3a7e42456d1dc3be7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/g185/AMLrepository/blob/main/RecipeNet/AML_Project_Giuliano.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXG6e2PquoqN"
      },
      "source": [
        "#***Download and unzip Dataset***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhlPBhD98p94"
      },
      "source": [
        "*   Create folders\n",
        "*   Download Recipe 5K + Annotations in drive\n",
        "*   Unzip files in folder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "KUrWflPRudbx",
        "outputId": "7c536d74-f3af-47a7-e08c-fdd65a533b31"
      },
      "source": [
        "#Create folders for models and datasets\n",
        "!mkdir \"/content/drive/My Drive/RecipeNet\" \n",
        "!mkdir \"/content/drive/My Drive/RecipeNet/datasets\" \n",
        "!mkdir \"/content/drive/My Drive/RecipeNet/datasets/download\" \n",
        "!mkdir \"/content/drive/My Drive/RecipeNet/datasets/extracted\" \n",
        "!mkdir \"/content/drive/My Drive/RecipeNet/datasets/preprocessed\" \n",
        "!mkdir \"/content/drive/My Drive/RecipeNet/model\" \n",
        "\n",
        "#Scarica dataset\n",
        "#Trascina i 3 zip\n",
        "\n",
        "#Unzip\n",
        "\"\"\"\n",
        "!unzip \"/content/drive/My Drive/RecipeNet/datasets/download/Recipes5k.zip\" -d \"/content/drive/My Drive/RecipeNet/datasets/extracted\"\n",
        "!unzip \"/content/drive/My Drive/RecipeNet/datasets/download/archive.zip\" -d \"/content/drive/My Drive/RecipeNet/datasets/extracted\"\n",
        "!unzip \"/content/drive/My Drive/RecipeNet/datasets/download/Ingredients101.zip\" -d \"/content/drive/My Drive/RecipeNet/datasets/extracted\"\n",
        "\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/My Drive/RecipeNet’: File exists\n",
            "mkdir: cannot create directory ‘/content/drive/My Drive/RecipeNet/datasets’: File exists\n",
            "mkdir: cannot create directory ‘/content/drive/My Drive/RecipeNet/datasets/download’: File exists\n",
            "mkdir: cannot create directory ‘/content/drive/My Drive/RecipeNet/datasets/extracted’: File exists\n",
            "mkdir: cannot create directory ‘/content/drive/My Drive/RecipeNet/model’: File exists\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n!unzip \"/content/drive/My Drive/RecipeNet/datasets/download/Recipes5k.zip\" -d \"/content/drive/My Drive/RecipeNet/datasets/extracted\"\\n!unzip \"/content/drive/My Drive/RecipeNet/datasets/download/archive.zip\" -d \"/content/drive/My Drive/RecipeNet/datasets/extracted\"\\n!unzip \"/content/drive/My Drive/RecipeNet/datasets/download/Ingredients101.zip\" -d \"/content/drive/My Drive/RecipeNet/datasets/extracted\"\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT-TwMVuBLEv"
      },
      "source": [
        "#***Imports and Drive Mount***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOJPDp-bU6rr",
        "outputId": "997067fd-85e9-4f21-deec-cf0a5aa9cd40"
      },
      "source": [
        "#Imports\n",
        "import sys\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from tqdm import tqdm, tqdm_notebook, tnrange\n",
        "import sys\n",
        "import cv2\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from glob import glob\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "#Cuda\n",
        "device = torch.device(\"cuda\")\n",
        "torch.manual_seed(42) # try and make the results more reproducible\n",
        "print(torch.cuda.get_device_name(0))\n",
        "\n",
        "#Drive Mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla P100-PCIE-16GB\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_AXoIoMB0om"
      },
      "source": [
        "#***Project Parameters***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYIvhj8aB4NV"
      },
      "source": [
        "params = {}\n",
        "params[\"root\"] = \"/content/drive/My Drive/RecipeNet/\"\n",
        "params[\"images_dir\"] = params[\"root\"] + \"datasets/extracted/images/\" \n",
        "params[\"ingredients_per_class\"] = params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/ingredients_simplified.txt\" \n",
        "params[\"classes\"] = params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/classes.txt\" \n",
        "params[\"baseIngredients_dir\"] = params[\"root\"] + \"datasets/extracted/Ingredients101/ingredients_simplification/baseIngredients.txt\" \n",
        "params[\"epochs\"] = 8\n",
        "params[\"batch_size\"] = 64\n",
        "params[\"img_size\"] = (384,384)\n",
        "params[\"fast_training\"] = True\n",
        "params[\"freezed_layers\"] = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzkRmamqNDt_"
      },
      "source": [
        "#***Data extraction and preprocessing***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5tPzq9WjV77"
      },
      "source": [
        "Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtUqblzXja33"
      },
      "source": [
        "#Ingredients x class\n",
        "f = open(params[\"ingredients_per_class\"], \"r\")\n",
        "ingredients = f.read().split('\\n')\n",
        "f.close()\n",
        "\n",
        "#Classes\n",
        "f = open(params[\"classes\"], \"r\")\n",
        "classes = f.read().split('\\n')\n",
        "f.close()\n",
        "\n",
        "#Ingredients\n",
        "f = open(params[\"baseIngredients_dir\"], \"r\")\n",
        "base_ing = f.read().split('\\n')\n",
        "base_ing = base_ing[0].split(\",\")\n",
        "f.close()\n",
        "\n",
        "#train images\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/train_images.txt\", \"r\")\n",
        "train_images = f.read().split('\\n')\n",
        "f.close()\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/train_labels.txt\", \"r\")\n",
        "train_labels = f.read().split('\\n')\n",
        "f.close()\n",
        "\n",
        "#validation images\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/val_images.txt\", \"r\")\n",
        "val_images = f.read().split('\\n')\n",
        "f.close()\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/val_labels.txt\", \"r\")\n",
        "val_labels = f.read().split('\\n')\n",
        "f.close()\n",
        "\n",
        "#test images\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/test_images.txt\", \"r\")\n",
        "test_images = f.read().split('\\n')\n",
        "f.close()\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/test_labels.txt\", \"r\")\n",
        "test_labels = f.read().split('\\n')\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URPn4rnyjjoj"
      },
      "source": [
        "Dataframes Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOoX41Sdjm3A"
      },
      "source": [
        "#list of string in list of list of tokens\n",
        "new_ingredients = [arr.split(\",\") for arr in ingredients]\n",
        "\n",
        "#binary encode ingredients\n",
        "mlb = MultiLabelBinarizer()\n",
        "df = pd.DataFrame(mlb.fit_transform(new_ingredients),columns=mlb.classes_) \n",
        "df[\"target\"] = classes\n",
        "food_dict = df\n",
        "\n",
        "train_images = [params[\"images_dir\"] + s + \".jpg\" for s in train_images]\n",
        "all_img_df = pd.DataFrame({'path': train_images, 'class_id': train_labels})\n",
        "val_images = [params[\"images_dir\"] + s + \".jpg\" for s in val_images]\n",
        "val_img_df = pd.DataFrame({'path': val_images, 'class_id': val_labels})\n",
        "test_images = [params[\"images_dir\"] + s + \".jpg\" for s in test_images]\n",
        "test_img_df = pd.DataFrame({'path': test_images, 'class_id': test_labels})\n",
        "all_img_df = all_img_df[:-1]\n",
        "val_img_df = val_img_df[:-1]\n",
        "test_img_df = test_img_df[:-1]\n",
        "\n",
        "\n",
        "\n",
        "all_img_df['class_name'] = all_img_df['path'].map(lambda x: os.path.split(os.path.dirname(x))[-1])\n",
        "val_img_df['class_name'] = val_img_df['path'].map(lambda x: os.path.split(os.path.dirname(x))[-1])\n",
        "test_img_df['class_name'] = test_img_df['path'].map(lambda x: os.path.split(os.path.dirname(x))[-1])\n",
        "\n",
        "food_dict = food_dict.drop('', 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "468oZbcTjzjI"
      },
      "source": [
        "Train Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su9RKGPwj3M7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "430b7c56-83d4-401d-af90-c06274e8f2cb"
      },
      "source": [
        "#Dataframe for train images\n",
        "new_data = []\n",
        "for index, row in all_img_df.iterrows():\n",
        "    #get binary encoding ingredients from lookup\n",
        "    food = row[\"class_name\"]\n",
        "    path = row[\"path\"]\n",
        "    class_id = row[\"class_id\"]\n",
        "    binary_encod = food_dict.loc[food_dict[\"target\"] == food]\n",
        "    binary_encod[\"path\"] = path\n",
        "    binary_encod[\"class_id\"] = class_id\n",
        "    #print(binary_encod)\n",
        "    #print((list(binary_encod.columns.values)))\n",
        "    #print(len(np.array(binary_encod)[0]))\n",
        "    new_data.append(np.array(binary_encod)[0])\n",
        "\n",
        "\n",
        "    \n",
        "col_names = list(binary_encod.columns.values)\n",
        "train_df = pd.DataFrame(new_data, columns = col_names)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTtejOUlj4l2"
      },
      "source": [
        "Validation Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE5pj15Ij75W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "278c8727-d9dc-4813-fd4b-ca7c6f634fea"
      },
      "source": [
        "val_data = []\n",
        "for index, row in val_img_df.iterrows():\n",
        "    #get binary encoding ingredients from lookup\n",
        "    food = row[\"class_name\"]\n",
        "    path = row[\"path\"]\n",
        "    class_id = row[\"class_id\"]\n",
        "    binary_encod = food_dict.loc[food_dict[\"target\"] == food]\n",
        "    binary_encod[\"path\"] = path\n",
        "    binary_encod[\"class_id\"] = int(class_id)\n",
        "    val_data.append(np.array(binary_encod)[0])\n",
        "val_df = pd.DataFrame(val_data, columns = col_names)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHK2_X4fj-l_"
      },
      "source": [
        "Test Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzdWTpbZeyap",
        "outputId": "c045361c-597e-4daf-d802-91728557198d"
      },
      "source": [
        "test_data = []\n",
        "for index, row in test_img_df.iterrows():\n",
        "    #get binary encoding ingredients from lookup\n",
        "    food = row[\"class_name\"]\n",
        "    path = row[\"path\"]\n",
        "    class_id = row[\"class_id\"]\n",
        "    binary_encod = food_dict.loc[food_dict[\"target\"] == food]\n",
        "    binary_encod[\"path\"] = path\n",
        "    binary_encod[\"class_id\"] = int(class_id)\n",
        "    test_data.append(np.array(binary_encod)[0])\n",
        "\n",
        "\n",
        "test_df = pd.DataFrame(test_data, columns = col_names)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unyTDi0vbuRC"
      },
      "source": [
        "#***DataGenerator***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CtfDNypczIt"
      },
      "source": [
        "class DataWrapper(data.Dataset):\n",
        "    ''' Data wrapper for pytorch's data loader function '''\n",
        "    def __init__(self, image_df, resize):\n",
        "        self.dataset = image_df\n",
        "        self.resize = resize\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        c_row = self.dataset.iloc[index]\n",
        "        target_arr = []\n",
        "        for item in c_row[targets].values:\n",
        "            target_arr.append(item)\n",
        "        #print(target_arr)\n",
        "        image_path, target = c_row['path'], torch.from_numpy(np.array(target_arr)).float()  #image and target\n",
        "        #read as rgb image, resize and convert to range 0 to 1\n",
        "        image = cv2.imread(image_path, 1)\n",
        "        if self.resize:\n",
        "            image = cv2.resize(image, params[\"img_size\"])/255.0 \n",
        "        else:\n",
        "            image = image/255.0\n",
        "        image = (torch.from_numpy(image.transpose(2,0,1))).float() #NxCxHxW\n",
        "        return image, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iZSnFTLNDim"
      },
      "source": [
        "#***Trasfer Learning Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bWUNYL4wdKR"
      },
      "source": [
        "col_names = list(train_df.columns.values)\n",
        "targets = col_names[:-3]\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "output = len(targets)\n",
        "model.fc = nn.Linear(model.fc.in_features, output)\n",
        "\n",
        "layer = 0\n",
        "for name, child in model.named_children():\n",
        "    layer += 1\n",
        "    if layer < params[\"freezed_layers\"]:\n",
        "        for name2, param in child.named_parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsKbUajgwOzk"
      },
      "source": [
        "#***DCNN Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7emD5fKnhG9f"
      },
      "source": [
        "model = ...."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgMUIGbwwtHO"
      },
      "source": [
        "#***Training***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tejkwYHPhx5o"
      },
      "source": [
        "Define Hamming Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1l7jgF4h83W"
      },
      "source": [
        "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
        "    '''\n",
        "    Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
        "    https://stackoverflow.com/q/32239577/395857\n",
        "    '''\n",
        "    acc_list = []\n",
        "    for i in range(y_true.shape[0]):\n",
        "        set_true = set( np.where(y_true[i])[0] )\n",
        "        set_pred = set( np.where(y_pred[i])[0] )\n",
        "        tmp_a = None\n",
        "        if len(set_true) == 0 and len(set_pred) == 0:\n",
        "            tmp_a = 1\n",
        "        else:\n",
        "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
        "                    float( len(set_true.union(set_pred)) )\n",
        "        acc_list.append(tmp_a)\n",
        "    return np.mean(acc_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5P5t3kOiWyN"
      },
      "source": [
        "Training Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAGn6B-hiZlR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75098134-099d-4ec8-cc49-3d63ffb27067"
      },
      "source": [
        "if params[\"fast_training\"] == True:\n",
        "    train_df = train_df[:13630]\n",
        "    val_df = val_df[:1515]\n",
        "    test_df = test_df[:5050]\n",
        "            \n",
        "print(len(val_df))\n",
        "model = model.to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4BOAUZSif36"
      },
      "source": [
        "Dataset Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN34WEC3iiLB"
      },
      "source": [
        "train_dataset = DataWrapper(train_df, True)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,shuffle=True, batch_size=params[\"batch_size\"], pin_memory=False)\n",
        "\n",
        "val_dataset = DataWrapper(val_df, True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset,shuffle=True, batch_size=params[\"batch_size\"], pin_memory=False)\n",
        "\n",
        "test_dataset = DataWrapper(test_df, True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,shuffle=True, batch_size=params[\"batch_size\"], pin_memory=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCjVOOL4i48a"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169,
          "referenced_widgets": [
            "c544f374f94e4472adecc7149f7975dc",
            "c237c15807ab4caab405eebe0b448890",
            "ed8c16a200fb4298bd3f5b8b240b9fc6",
            "8292618672b74f8ca276e1c8cd932dd9",
            "5a7abbb46ba24bce85211190ef19ec1a",
            "305764fc917d46a0901679d203f82918",
            "ebbabb96001941fdb747aa15a6e70a1f",
            "bb77e4a8f0fa434f825caad2c9927155",
            "e3d40bc28f7745dc8e09761f25442deb",
            "ef002da610304eea9201faa6f8da9eed",
            "36184149091e45f9b416d4c757371927",
            "d4e906d01a884c9bad6b3b31997fef50",
            "1deee7e1bb9c4bd799cc2f33dd51bcf5",
            "254ccfa0c5df40818f8a777985a8cf05",
            "57abc6db510343588a9da876702fc71a",
            "59827b894fc94ef3a7e42456d1dc3be7"
          ]
        },
        "id": "THX6oDqxqblX",
        "outputId": "b59664ab-f861-4d1f-db95-153d6bbe6902"
      },
      "source": [
        "\n",
        "train_results = defaultdict(list)\n",
        "train_iter, test_iter, best_acc = 0,0,0\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize = (10, 10))\n",
        "ax1.set_title('Train Loss')\n",
        "ax2.set_title('Train Accuracy')\n",
        "ax3.set_title('Test Loss')\n",
        "ax4.set_title('Test Accuracy')\n",
        "\n",
        "f1_scores = defaultdict(list)\n",
        "for i in tnrange(params[\"epochs\"], desc='Epochs'):\n",
        "    print(\"Epoch \",i)\n",
        "    ## Train Phase\n",
        "    #Model switches to train phase\n",
        "    model.train() \n",
        "    \n",
        "    all_outputs = []\n",
        "    all_targets = []\n",
        "    # Running through all mini batches in the dataset\n",
        "    count, loss_val, correct, total = train_iter, 0, 0, 0\n",
        "    for img_data, target in tqdm_notebook(train_loader, desc='Training'):    \n",
        "        img_data, target = img_data.to(device), target.to(device)\n",
        "        \n",
        "        output = model(img_data) #FWD prop\n",
        "\n",
        "        loss = criterion(output, target) #Cross entropy loss\n",
        "        c_loss = loss.data.item()\n",
        "        ax1.plot(count, c_loss, 'r.')\n",
        "        loss_val += c_loss\n",
        "\n",
        "        optimizer.zero_grad() #Zero out any cached gradients\n",
        "        loss.backward() #Backward pass\n",
        "        optimizer.step() #Update the weights\n",
        "\n",
        "        total_batch = (target.size(0) * target.size(1))\n",
        "        total += total_batch\n",
        "        output_data = torch.sigmoid(output)>=0.5\n",
        "        target_data = (target==1.0)\n",
        "        for arr1,arr2 in zip(output_data, target_data):\n",
        "            all_outputs.append(list(arr1.cpu().numpy()))\n",
        "            all_targets.append(list(arr2.cpu().numpy()))\n",
        "        c_acc = torch.sum((output_data == target_data.to(device)).to(torch.float)).item()\n",
        "        ax2.plot(count, c_acc/total_batch, 'r.')\n",
        "        correct += c_acc\n",
        "        count +=1\n",
        "        \n",
        "    all_outputs = np.array(all_outputs)\n",
        "    all_targets = np.array(all_targets)\n",
        "    f1score_samples = f1_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    f1score_macro = f1_score(y_true=all_targets, y_pred=all_outputs, average='macro')\n",
        "    f1score_weighted = f1_score(y_true=all_targets, y_pred=all_outputs, average='weighted')\n",
        "    recall = recall_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    prec = precision_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    hamming = hamming_score(y_true=all_targets, y_pred=all_outputs)\n",
        "    \n",
        "    f1_scores[\"samples_train\"].append(f1score_samples)\n",
        "    f1_scores[\"macro_train\"].append(f1score_macro)\n",
        "    f1_scores[\"weighted_train\"].append(f1score_weighted)\n",
        "    f1_scores[\"hamming_train\"].append(hamming)\n",
        "    \n",
        "    train_loss_val, train_iter, train_acc = loss_val/len(train_loader.dataset), count, correct/float(total)\n",
        "    \n",
        "    print(\"Training loss: \", train_loss_val, \" train acc: \",train_acc)    \n",
        "    ## Test Phase\n",
        "    \n",
        "    #Model switches to test phase\n",
        "    model.eval()\n",
        "    \n",
        "    all_outputs = []\n",
        "    all_targets = []\n",
        "    #Running through all mini batches in the dataset\n",
        "    count, correct, total, lost_val = test_iter, 0, 0, 0\n",
        "    for img_data, target in tqdm_notebook(val_loader, desc='Testing'):\n",
        "        img_data, target = img_data.to(device), target.to(device)\n",
        "        output = model(img_data)\n",
        "        loss = criterion(output, target) #Cross entropy loss\n",
        "        c_loss = loss.data.item()\n",
        "        ax3.plot(count, c_loss, 'b.')\n",
        "        loss_val += c_loss\n",
        "        #Compute accuracy\n",
        "        #predicted = output.data.max(1)[1] #get index of max\n",
        "        total_batch = (target.size(0) * target.size(1))\n",
        "        total += total_batch\n",
        "        output_data = torch.sigmoid(output)>=0.5\n",
        "        target_data = (target==1.0)\n",
        "        #print(\"Predictions: \", output_data)\n",
        "        #print(\"Actual: \", target_data)\n",
        "        for arr1,arr2 in zip(output_data, target_data):\n",
        "            all_outputs.append(list(arr1.cpu().numpy()))\n",
        "            all_targets.append(list(arr2.cpu().numpy()))\n",
        "        c_acc = torch.sum((output_data == target_data.to(device)).to(torch.float)).item()\n",
        "        ax4.plot(count, c_acc/total_batch, 'b.')\n",
        "        correct += c_acc\n",
        "        count += 1\n",
        "    \n",
        "    #print(\"Outputs: \", len(all_outputs), \" x \", len(all_outputs[0]))\n",
        "    #print(\"Targets: \", len(all_targets), \" x \", len(all_targets[0]))\n",
        "    \n",
        "    #F1 Score\n",
        "    all_outputs = np.array(all_outputs)\n",
        "    all_targets = np.array(all_targets)\n",
        "    f1score_samples = f1_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    f1score_macro = f1_score(y_true=all_targets, y_pred=all_outputs, average='macro')\n",
        "    f1score_weighted = f1_score(y_true=all_targets, y_pred=all_outputs, average='weighted')\n",
        "    recall = recall_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    prec = precision_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    hamming = hamming_score(y_true=all_targets, y_pred=all_outputs)\n",
        "    \n",
        "    f1_scores[\"samples_test\"].append(f1score_samples)\n",
        "    f1_scores[\"macro_test\"].append(f1score_macro)\n",
        "    f1_scores[\"weighted_test\"].append(f1score_weighted)\n",
        "    f1_scores[\"hamming_test\"].append(hamming)\n",
        "    \n",
        "    #Accuracy over entire dataset\n",
        "    test_acc, test_iter, test_loss_val = correct/float(total), count, loss_val/len(test_loader.dataset)\n",
        "    print(\"Test set accuracy: \",test_acc)\n",
        "    print(\"f1_scores\", f1_scores)\n",
        "    train_results['epoch'].append(i)\n",
        "    train_results['train_loss'].append(train_loss_val)\n",
        "    train_results['train_acc'].append(train_acc)\n",
        "    train_results['train_iter'].append(train_iter)\n",
        "    \n",
        "    train_results['test_loss'].append(test_loss_val)\n",
        "    train_results['test_acc'].append(test_acc)\n",
        "    train_results['test_iter'].append(test_iter)\n",
        "    \n",
        "    #Save model with best accuracy\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        torch.save(model.state_dict(), 'best_model.pth') \n",
        "fig.savefig('train_curves.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c544f374f94e4472adecc7149f7975dc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epochs', max=8.0, style=ProgressStyle(description_width='…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3d40bc28f7745dc8e09761f25442deb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Training', max=213.0, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HgLjKiPkMLn"
      },
      "source": [
        "#***Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmFAVmC8kRFp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}