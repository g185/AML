{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy_of_AML_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UXG6e2PquoqN"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0508adf9e6c24f4487b6db98fe11f01c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_33d57a4e9d854d8e82b15b922537142e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d3ee2f2654e2445db88b0730898f5eea",
              "IPY_MODEL_c77a6d2a5464428990d3287191ad3f52"
            ]
          }
        },
        "33d57a4e9d854d8e82b15b922537142e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3ee2f2654e2445db88b0730898f5eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_428df36e3372437d830b52787fd990f2",
            "_dom_classes": [],
            "description": "Epochs:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 8,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b99288a869a14aacb515ee2eb63fd4bf"
          }
        },
        "c77a6d2a5464428990d3287191ad3f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3d8571d94501442e9a80b29a3ef099dd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/8 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_832ca0ed5543401595c6266f95a1a99c"
          }
        },
        "428df36e3372437d830b52787fd990f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b99288a869a14aacb515ee2eb63fd4bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d8571d94501442e9a80b29a3ef099dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "832ca0ed5543401595c6266f95a1a99c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd1c5307dc4b4be5a3fb42a8adb4d48d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a04fceae676142a1bf1f260403ff1963",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_be7ec57185d943558703f4e08693be22",
              "IPY_MODEL_66f848e190bc4ffb8dd26bcca84674fa"
            ]
          }
        },
        "a04fceae676142a1bf1f260403ff1963": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be7ec57185d943558703f4e08693be22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_89b9489186ee44179f32c2931576fbd5",
            "_dom_classes": [],
            "description": "Training:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 19,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7ac187c67334a588a380ee7b4090daf"
          }
        },
        "66f848e190bc4ffb8dd26bcca84674fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bad8c7038cae41aa856b9fc6eea0e187",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/19 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ade5098897cf44598fd3690b42dff28e"
          }
        },
        "89b9489186ee44179f32c2931576fbd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a7ac187c67334a588a380ee7b4090daf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bad8c7038cae41aa856b9fc6eea0e187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ade5098897cf44598fd3690b42dff28e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6e8216ec492b440b9fb41928a0770f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c55cc74f5c204699b884ee88a3200ecb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ad55b8ecd4ba4cc1b7f989b44a7cd3e2",
              "IPY_MODEL_72b5a4c17a5f42bf94ab5713db4250e8"
            ]
          }
        },
        "c55cc74f5c204699b884ee88a3200ecb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad55b8ecd4ba4cc1b7f989b44a7cd3e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_39992ba5d1db450191e5694e25bbbdb5",
            "_dom_classes": [],
            "description": "Testing: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 19,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 19,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bedca18a35cc4de98169e01fd55d6227"
          }
        },
        "72b5a4c17a5f42bf94ab5713db4250e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_27116289ed7a4fa2ac648f859e0404cc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 19/19 [00:16&lt;00:00,  1.18it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5058c5cd6e545cc882b9faf5a260a8b"
          }
        },
        "39992ba5d1db450191e5694e25bbbdb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bedca18a35cc4de98169e01fd55d6227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27116289ed7a4fa2ac648f859e0404cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5058c5cd6e545cc882b9faf5a260a8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/g185/AMLrepository/blob/main/RecipeNet/AML_Project_Giuliano.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXG6e2PquoqN"
      },
      "source": [
        "#***Download and unzip Dataset***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhlPBhD98p94"
      },
      "source": [
        "*   Create folders\n",
        "*   Download Recipe 5K + Annotations in drive\n",
        "*   Unzip files in folder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "KUrWflPRudbx",
        "outputId": "7c536d74-f3af-47a7-e08c-fdd65a533b31"
      },
      "source": [
        "#Create folders for models and datasets\n",
        "!mkdir \"/content/drive/My Drive/RecipeNet\" \n",
        "!mkdir \"/content/drive/My Drive/RecipeNet/datasets\" \n",
        "!mkdir \"/content/drive/My Drive/RecipeNet/datasets/download\" \n",
        "!mkdir \"/content/drive/My Drive/RecipeNet/datasets/extracted\" \n",
        "!mkdir \"/content/drive/My Drive/RecipeNet/datasets/preprocessed\" \n",
        "!mkdir \"/content/drive/My Drive/RecipeNet/model\" \n",
        "\n",
        "#Scarica dataset\n",
        "#Trascina i 3 zip\n",
        "\n",
        "#Unzip\n",
        "\"\"\"\n",
        "!unzip \"/content/drive/My Drive/RecipeNet/datasets/download/Recipes5k.zip\" -d \"/content/drive/My Drive/RecipeNet/datasets/extracted\"\n",
        "!unzip \"/content/drive/My Drive/RecipeNet/datasets/download/archive.zip\" -d \"/content/drive/My Drive/RecipeNet/datasets/extracted\"\n",
        "!unzip \"/content/drive/My Drive/RecipeNet/datasets/download/Ingredients101.zip\" -d \"/content/drive/My Drive/RecipeNet/datasets/extracted\"\n",
        "\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory â€˜/content/drive/My Drive/RecipeNetâ€™: File exists\n",
            "mkdir: cannot create directory â€˜/content/drive/My Drive/RecipeNet/datasetsâ€™: File exists\n",
            "mkdir: cannot create directory â€˜/content/drive/My Drive/RecipeNet/datasets/downloadâ€™: File exists\n",
            "mkdir: cannot create directory â€˜/content/drive/My Drive/RecipeNet/datasets/extractedâ€™: File exists\n",
            "mkdir: cannot create directory â€˜/content/drive/My Drive/RecipeNet/modelâ€™: File exists\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n!unzip \"/content/drive/My Drive/RecipeNet/datasets/download/Recipes5k.zip\" -d \"/content/drive/My Drive/RecipeNet/datasets/extracted\"\\n!unzip \"/content/drive/My Drive/RecipeNet/datasets/download/archive.zip\" -d \"/content/drive/My Drive/RecipeNet/datasets/extracted\"\\n!unzip \"/content/drive/My Drive/RecipeNet/datasets/download/Ingredients101.zip\" -d \"/content/drive/My Drive/RecipeNet/datasets/extracted\"\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT-TwMVuBLEv"
      },
      "source": [
        "#***Imports and Drive Mount***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOJPDp-bU6rr",
        "outputId": "bf47d25e-6bb3-4705-88f1-533d8543ac68"
      },
      "source": [
        "#Imports\n",
        "import sys\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from tqdm import tqdm, tqdm_notebook, tnrange\n",
        "import sys\n",
        "import cv2\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from glob import glob\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "#Cuda\n",
        "device = torch.device(\"cuda\")\n",
        "torch.manual_seed(42) # try and make the results more reproducible\n",
        "print(torch.cuda.get_device_name(0))\n",
        "\n",
        "#Drive Mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla P100-PCIE-16GB\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_AXoIoMB0om"
      },
      "source": [
        "#***Project Parameters***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYIvhj8aB4NV"
      },
      "source": [
        "params = {}\n",
        "params[\"root\"] = \"/content/drive/My Drive/RecipeNet/\"\n",
        "\n",
        "\n",
        "params[\"dataset\"] = \"Recipe5k\"\n",
        "params[\"fast_training\"] = True\n",
        "\n",
        "\n",
        "if params[\"dataset\"] == \"Recipe1M\":\n",
        "  params[\"images_dir\"] = params[\"root\"] + \"datasets/extracted/images/\" \n",
        "  params[\"ingredients_per_class\"] = params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/ingredients_simplified.txt\" \n",
        "  params[\"classes\"] = params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/classes.txt\" \n",
        "  params[\"baseIngredients_dir\"] = params[\"root\"] + \"datasets/extracted/Ingredients101/ingredients_simplification/baseIngredients.txt\" \n",
        "else:\n",
        "  params[\"images_dir\"] = params[\"root\"] + \"datasets/extracted/right_train/\" \n",
        "  params[\"ingredients_per_class\"] = params[\"root\"] + \"datasets/extracted/Annotations_1M/ingr.txt\" \n",
        "  params[\"classes\"] = params[\"root\"] + \"datasets/extracted/Annotations_1M/newclasses.txt\" \n",
        "  params[\"baseIngredients_dir\"] = params[\"root\"] + \"datasets/extracted/Annotations_1M/baseIngredients.txt\" \n",
        " \n",
        "\n",
        "params[\"epochs\"] = 8\n",
        "params[\"batch_size\"] = 64\n",
        "params[\"img_size\"] = (384,384)\n",
        "params[\"freezed_layers\"] = 8"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzkRmamqNDt_"
      },
      "source": [
        "#***Data extraction and preprocessing***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5tPzq9WjV77"
      },
      "source": [
        "Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtUqblzXja33",
        "outputId": "8b8cacca-b318-4025-8a7f-82420471773c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Ingredients x class\n",
        "f = open(params[\"ingredients_per_class\"], \"r\")\n",
        "ingredients = f.read().split('\\n')\n",
        "f.close()\n",
        "\n",
        "#Classes\n",
        "f = open(params[\"classes\"], \"r\")\n",
        "classes = f.read().split('\\n')\n",
        "f.close()\n",
        "\n",
        "#Ingredients\n",
        "f = open(params[\"baseIngredients_dir\"], \"r\")\n",
        "base_ing = f.read().split('\\n')\n",
        "base_ing = base_ing[0].split(\",\")\n",
        "f.close()\n",
        "\n",
        "#train images\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Annotations_1M/train_imgs.txt\", \"r\")\n",
        "train_images = f.read().split('\\n')\n",
        "print(train_images[:10])\n",
        "f.close()\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Annotations_1M/train_lab.txt\", \"r\")\n",
        "train_labels = f.read().split('\\n')\n",
        "f.close()\n",
        "\n",
        "#validation images\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Annotations_1M/val_imgs.txt\", \"r\")\n",
        "val_images = f.read().split('\\n')\n",
        "f.close()\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Annotations_1M/val_lab.txt\", \"r\")\n",
        "val_labels = f.read().split('\\n')\n",
        "f.close()\n",
        "\n",
        "#test images\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Annotations_1M/test_imgs.txt\", \"r\")\n",
        "test_images = f.read().split('\\n')\n",
        "f.close()\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Annotations_1M/test_lab.txt\", \"r\")\n",
        "test_labels = f.read().split('\\n')\n",
        "f.close()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['abaaa34e8a/0035498b8f', 'abaaa34e8a/00df971801', 'abaaa34e8a/066678055e', 'abaaa34e8a/066ec853e4', 'abaaa34e8a/0aec8e4dcd', 'abaaa34e8a/0da78b2496', 'abaaa34e8a/11c8ab8249', 'abaaa34e8a/11dc55ff6a', 'abaaa34e8a/127fe16291', 'abaaa34e8a/16da2ef4b8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBk379JUxzjA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URPn4rnyjjoj"
      },
      "source": [
        "Dataframes Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOoX41Sdjm3A",
        "outputId": "96138426-8b0c-4697-f4af-f2f90626a2c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#list of string in list of list of tokens\n",
        "new_ingredients = [arr.split(\",\") for arr in ingredients]\n",
        "\n",
        "#binary encode ingredients\n",
        "mlb = MultiLabelBinarizer()\n",
        "df = pd.DataFrame(mlb.fit_transform(new_ingredients),columns=mlb.classes_) \n",
        "df[\"target\"] = classes\n",
        "food_dict = df\n",
        "print(train_images[:10])\n",
        "train_images = [params[\"images_dir\"] + s + \".jpg\" for s in train_images]\n",
        "print(train_images[:10])\n",
        "all_img_df = pd.DataFrame({'path': train_images, 'class_id': train_labels})\n",
        "val_images = [params[\"images_dir\"] + s + \".jpg\" for s in val_images]\n",
        "val_img_df = pd.DataFrame({'path': val_images, 'class_id': val_labels})\n",
        "test_images = [params[\"images_dir\"] + s + \".jpg\" for s in test_images]\n",
        "test_img_df = pd.DataFrame({'path': test_images, 'class_id': test_labels})\n",
        "all_img_df = all_img_df[:-1]\n",
        "val_img_df = val_img_df[:-1]\n",
        "test_img_df = test_img_df[:-1]\n",
        "\n",
        "\n",
        "\n",
        "all_img_df['class_name'] = all_img_df['path'].map(lambda x: os.path.split(os.path.dirname(x))[-1])\n",
        "val_img_df['class_name'] = val_img_df['path'].map(lambda x: os.path.split(os.path.dirname(x))[-1])\n",
        "test_img_df['class_name'] = test_img_df['path'].map(lambda x: os.path.split(os.path.dirname(x))[-1])\n",
        "\n",
        "#food_dict = food_dict.drop('', 1)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['abaaa34e8a/0035498b8f', 'abaaa34e8a/00df971801', 'abaaa34e8a/066678055e', 'abaaa34e8a/066ec853e4', 'abaaa34e8a/0aec8e4dcd', 'abaaa34e8a/0da78b2496', 'abaaa34e8a/11c8ab8249', 'abaaa34e8a/11dc55ff6a', 'abaaa34e8a/127fe16291', 'abaaa34e8a/16da2ef4b8']\n",
            "['/content/drive/My Drive/RecipeNet/datasets/extracted/right_train/abaaa34e8a/0035498b8f.jpg', '/content/drive/My Drive/RecipeNet/datasets/extracted/right_train/abaaa34e8a/00df971801.jpg', '/content/drive/My Drive/RecipeNet/datasets/extracted/right_train/abaaa34e8a/066678055e.jpg', '/content/drive/My Drive/RecipeNet/datasets/extracted/right_train/abaaa34e8a/066ec853e4.jpg', '/content/drive/My Drive/RecipeNet/datasets/extracted/right_train/abaaa34e8a/0aec8e4dcd.jpg', '/content/drive/My Drive/RecipeNet/datasets/extracted/right_train/abaaa34e8a/0da78b2496.jpg', '/content/drive/My Drive/RecipeNet/datasets/extracted/right_train/abaaa34e8a/11c8ab8249.jpg', '/content/drive/My Drive/RecipeNet/datasets/extracted/right_train/abaaa34e8a/11dc55ff6a.jpg', '/content/drive/My Drive/RecipeNet/datasets/extracted/right_train/abaaa34e8a/127fe16291.jpg', '/content/drive/My Drive/RecipeNet/datasets/extracted/right_train/abaaa34e8a/16da2ef4b8.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "468oZbcTjzjI"
      },
      "source": [
        "Train Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su9RKGPwj3M7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0991d39e-59d2-490b-c5c5-e590e0f89a71"
      },
      "source": [
        "#Dataframe for train images\n",
        "new_data = []\n",
        "for index, row in all_img_df.iterrows():\n",
        "    #get binary encoding ingredients from lookup\n",
        "    food = row[\"class_name\"]\n",
        "    path = row[\"path\"]\n",
        "    class_id = row[\"class_id\"]\n",
        "    binary_encod = food_dict.loc[food_dict[\"target\"] == food]\n",
        "    binary_encod[\"path\"] = path\n",
        "    binary_encod[\"class_id\"] = class_id\n",
        "    #print(binary_encod[\"class_id\"])\n",
        "    #print((list(binary_encod.columns.values)))\n",
        "    #print(len(np.array(binary_encod)[0]))\n",
        "    new_data.append(np.array(binary_encod)[0])\n",
        "\n",
        "\n",
        "    \n",
        "col_names = list(binary_encod.columns.values)\n",
        "train_df = pd.DataFrame(new_data, columns = col_names)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTtejOUlj4l2"
      },
      "source": [
        "Validation Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE5pj15Ij75W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3b7f495-b1e6-4232-ff9c-1b1605b24591"
      },
      "source": [
        "val_data = []\n",
        "for index, row in val_img_df.iterrows():\n",
        "    #get binary encoding ingredients from lookup\n",
        "    food = row[\"class_name\"]\n",
        "    path = row[\"path\"]\n",
        "    class_id = row[\"class_id\"]\n",
        "    binary_encod = food_dict.loc[food_dict[\"target\"] == food]\n",
        "    binary_encod[\"path\"] = path\n",
        "    binary_encod[\"class_id\"] = int(class_id)\n",
        "    val_data.append(np.array(binary_encod)[0])\n",
        "val_df = pd.DataFrame(val_data, columns = col_names)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHK2_X4fj-l_"
      },
      "source": [
        "Test Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzdWTpbZeyap",
        "outputId": "8e635c5a-6b82-489d-8142-6c11d0953861"
      },
      "source": [
        "test_data = []\n",
        "for index, row in test_img_df.iterrows():\n",
        "    #get binary encoding ingredients from lookup\n",
        "    food = row[\"class_name\"]\n",
        "    path = row[\"path\"]\n",
        "    class_id = row[\"class_id\"]\n",
        "    binary_encod = food_dict.loc[food_dict[\"target\"] == food]\n",
        "    binary_encod[\"path\"] = path\n",
        "    binary_encod[\"class_id\"] = int(class_id)\n",
        "    test_data.append(np.array(binary_encod)[0])\n",
        "\n",
        "\n",
        "test_df = pd.DataFrame(test_data, columns = col_names)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unyTDi0vbuRC"
      },
      "source": [
        "#***DataGenerator***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CtfDNypczIt"
      },
      "source": [
        "class DataWrapper(data.Dataset):\n",
        "    ''' Data wrapper for pytorch's data loader function '''\n",
        "    def __init__(self, image_df, resize):\n",
        "        self.dataset = image_df\n",
        "        self.resize = resize\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        c_row = self.dataset.iloc[index]\n",
        "        target_arr = []\n",
        "        for item in c_row[targets].values:\n",
        "            target_arr.append(item)\n",
        "        #print(target_arr)\n",
        "        image_path, target = c_row['path'], torch.from_numpy(np.array(target_arr)).float()  #image and target\n",
        "        #read as rgb image, resize and convert to range 0 to 1\n",
        "        image = cv2.imread(image_path, 1)\n",
        "        print(image_path, image)\n",
        "        if self.resize:\n",
        "            image = cv2.resize(image, params[\"img_size\"])/255.0 \n",
        "        else:\n",
        "            image = image/255.0\n",
        "        image = (torch.from_numpy(image.transpose(2,0,1))).float() #NxCxHxW\n",
        "        return image, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset.shape[0]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iZSnFTLNDim"
      },
      "source": [
        "#***Trasfer Learning Model:ResNet***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bWUNYL4wdKR"
      },
      "source": [
        "col_names = list(train_df.columns.values)\n",
        "targets = col_names[:-3]\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "output = len(targets)\n",
        "model.fc = nn.Linear(model.fc.in_features, output)\n",
        "\n",
        "layer = 0\n",
        "for name, child in model.named_children():\n",
        "    layer += 1\n",
        "    if layer < params[\"freezed_layers\"]:\n",
        "        for name2, param in child.named_parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh3cb4XkWEDN"
      },
      "source": [
        "#***Trasfer Learning Model:GoogleNet***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAOZoiqfWEDg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgMUIGbwwtHO"
      },
      "source": [
        "#***Training***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tejkwYHPhx5o"
      },
      "source": [
        "Define Hamming Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1l7jgF4h83W"
      },
      "source": [
        "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
        "    '''\n",
        "    Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
        "    https://stackoverflow.com/q/32239577/395857\n",
        "    '''\n",
        "    acc_list = []\n",
        "    for i in range(y_true.shape[0]):\n",
        "        set_true = set( np.where(y_true[i])[0] )\n",
        "        set_pred = set( np.where(y_pred[i])[0] )\n",
        "        tmp_a = None\n",
        "        if len(set_true) == 0 and len(set_pred) == 0:\n",
        "            tmp_a = 1\n",
        "        else:\n",
        "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
        "                    float( len(set_true.union(set_pred)) )\n",
        "        acc_list.append(tmp_a)\n",
        "    return np.mean(acc_list)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5P5t3kOiWyN"
      },
      "source": [
        "Training Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAGn6B-hiZlR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b90cd9c-7f32-4827-d906-81c3818c97db"
      },
      "source": [
        "if params[\"fast_training\"] == True:\n",
        "    train_df = train_df[:1200]\n",
        "    val_df = val_df[:1200]\n",
        "    test_df = test_df[:1200]\n",
        "            \n",
        "print(len(val_df))\n",
        "model = model.to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4BOAUZSif36"
      },
      "source": [
        "Dataset Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN34WEC3iiLB"
      },
      "source": [
        "train_dataset = DataWrapper(train_df, True)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,shuffle=True, batch_size=params[\"batch_size\"], pin_memory=False)\n",
        "\n",
        "val_dataset = DataWrapper(val_df, True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset,shuffle=True, batch_size=params[\"batch_size\"], pin_memory=False)\n",
        "\n",
        "test_dataset = DataWrapper(test_df, True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,shuffle=True, batch_size=params[\"batch_size\"], pin_memory=False)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCjVOOL4i48a"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0508adf9e6c24f4487b6db98fe11f01c",
            "33d57a4e9d854d8e82b15b922537142e",
            "d3ee2f2654e2445db88b0730898f5eea",
            "c77a6d2a5464428990d3287191ad3f52",
            "428df36e3372437d830b52787fd990f2",
            "b99288a869a14aacb515ee2eb63fd4bf",
            "3d8571d94501442e9a80b29a3ef099dd",
            "832ca0ed5543401595c6266f95a1a99c",
            "fd1c5307dc4b4be5a3fb42a8adb4d48d",
            "a04fceae676142a1bf1f260403ff1963",
            "be7ec57185d943558703f4e08693be22",
            "66f848e190bc4ffb8dd26bcca84674fa",
            "89b9489186ee44179f32c2931576fbd5",
            "a7ac187c67334a588a380ee7b4090daf",
            "bad8c7038cae41aa856b9fc6eea0e187",
            "ade5098897cf44598fd3690b42dff28e"
          ]
        },
        "id": "THX6oDqxqblX",
        "outputId": "2b144af0-46ce-4eeb-c7c9-34cb7fa7890e"
      },
      "source": [
        "#Definisco i plots\n",
        "train_results = defaultdict(list)\n",
        "train_iter, test_iter, best_acc = 0,0,0\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize = (10, 10))\n",
        "ax1.set_title('Train Loss')\n",
        "ax2.set_title('Train Accuracy')\n",
        "ax3.set_title('Test Loss')\n",
        "ax4.set_title('Test Accuracy')\n",
        "\n",
        "#dizionario f1 scores\n",
        "f1_scores = defaultdict(list)\n",
        "\n",
        "for i in tnrange(params[\"epochs\"], desc='Epochs'):\n",
        "    print(\"Epoch \",i)\n",
        "    ## Train Phase\n",
        "    #Model switches to train phase\n",
        "    model.train() \n",
        "    \n",
        "    #azzera ris\n",
        "    all_outputs = []\n",
        "    all_targets = []\n",
        "\n",
        "    # Running through all mini batches in the dataset\n",
        "    count, loss_val, correct, total = train_iter, 0, 0, 0\n",
        "    for img_data, target in tqdm_notebook(train_loader, desc='Training'):  \n",
        "\n",
        "        #load batch  \n",
        "        img_data, target = img_data.to(device), target.to(device)\n",
        "\n",
        "        #FWD prop\n",
        "        output = model(img_data) \n",
        "\n",
        "        #Cross entropy loss\n",
        "        loss = criterion(output, target) \n",
        "\n",
        "        #current loss \n",
        "        c_loss = loss.data.item()\n",
        "\n",
        "        #plot current loss\n",
        "        ax1.plot(count, c_loss, 'r.')\n",
        "\n",
        "        #accumulate loss for training phase\n",
        "        loss_val += c_loss\n",
        "\n",
        "        optimizer.zero_grad() #Zero out any cached gradients\n",
        "        loss.backward() #Backward pass\n",
        "        optimizer.step() #Update the weights\n",
        "\n",
        "        #number of outputs, batch * labels\n",
        "        total_batch = (target.size(0) * target.size(1))\n",
        "        total += total_batch\n",
        "\n",
        "        #output and targets\n",
        "        output_data = torch.sigmoid(output)>=0.5\n",
        "        target_data = (target==1.0)\n",
        "        \n",
        "        #carica i risultati e i target\n",
        "        for arr1,arr2 in zip(output_data, target_data):\n",
        "            all_outputs.append(list(arr1.cpu().numpy()))\n",
        "            all_targets.append(list(arr2.cpu().numpy()))\n",
        "\n",
        "        #accuracy\n",
        "        c_acc = torch.sum((output_data == target_data.to(device)).to(torch.float)).item()\n",
        "        \n",
        "        #plot accuracy\n",
        "        ax2.plot(count, c_acc/total_batch, 'r.')\n",
        "\n",
        "        #accumula accuracy\n",
        "        correct += c_acc\n",
        "\n",
        "        #accumula numero di steps per epoch\n",
        "        count +=1\n",
        "        \n",
        "    #prendi i risultati dell'ultimo training\n",
        "    all_outputs = np.array(all_outputs)\n",
        "    all_targets = np.array(all_targets)\n",
        "\n",
        "    #Training Metrics\n",
        "    #______________________________________________________________________________________________________\n",
        "    f1score_samples = f1_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    f1score_macro = f1_score(y_true=all_targets, y_pred=all_outputs, average='macro')\n",
        "    f1score_weighted = f1_score(y_true=all_targets, y_pred=all_outputs, average='weighted')\n",
        "    recall = recall_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    prec = precision_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    hamming = hamming_score(y_true=all_targets, y_pred=all_outputs)\n",
        "    \n",
        "    f1_scores[\"samples_train\"].append(f1score_samples)\n",
        "    f1_scores[\"macro_train\"].append(f1score_macro)\n",
        "    f1_scores[\"weighted_train\"].append(f1score_weighted)\n",
        "    f1_scores[\"hamming_train\"].append(hamming)\n",
        "    #____________________________________________________________________________________________________________________\n",
        "    #Training loss val Ã¨ loss per image,\n",
        "    #train_iter Ã¨ count, numero di steps, images in training / batch size * epoch number\n",
        "    #train_acc over training\n",
        "    train_loss_val, train_iter, train_acc = loss_val/len(train_loader.dataset), count, correct/float(total)\n",
        "    \n",
        "    print(\"Training loss: \", train_loss_val, \" train acc: \",train_acc)    \n",
        "    ## Test Phase\n",
        "    \n",
        "    #Model switches to test phase\n",
        "    model.eval()\n",
        "    \n",
        "    all_outputs = []\n",
        "    all_targets = []\n",
        "    #Running through all mini batches in the dataset\n",
        "    count, correct, total, lost_val = test_iter, 0, 0, 0\n",
        "    for img_data, target in tqdm_notebook(val_loader, desc='Validation'):\n",
        "        img_data, target = img_data.to(device), target.to(device)\n",
        "        output = model(img_data)\n",
        "        loss = criterion(output, target) #Cross entropy loss\n",
        "        c_loss = loss.data.item()\n",
        "        ax3.plot(count, c_loss, 'b.')\n",
        "        loss_val += c_loss\n",
        "        #Compute accuracy\n",
        "        #predicted = output.data.max(1)[1] #get index of max\n",
        "        total_batch = (target.size(0) * target.size(1))\n",
        "        total += total_batch\n",
        "        output_data = torch.sigmoid(output)>=0.5\n",
        "        target_data = (target==1.0)\n",
        "        #print(\"Predictions: \", output_data)\n",
        "        #print(\"Actual: \", target_data)\n",
        "        for arr1,arr2 in zip(output_data, target_data):\n",
        "            all_outputs.append(list(arr1.cpu().numpy()))\n",
        "            all_targets.append(list(arr2.cpu().numpy()))\n",
        "        c_acc = torch.sum((output_data == target_data.to(device)).to(torch.float)).item()\n",
        "        ax4.plot(count, c_acc/total_batch, 'b.')\n",
        "        correct += c_acc\n",
        "        count += 1\n",
        "    \n",
        "    #print(\"Outputs: \", len(all_outputs), \" x \", len(all_outputs[0]))\n",
        "    #print(\"Targets: \", len(all_targets), \" x \", len(all_targets[0]))\n",
        "    \n",
        "    #F1 Score\n",
        "    all_outputs = np.array(all_outputs)\n",
        "    all_targets = np.array(all_targets)\n",
        "    f1score_samples = f1_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    f1score_macro = f1_score(y_true=all_targets, y_pred=all_outputs, average='macro')\n",
        "    f1score_weighted = f1_score(y_true=all_targets, y_pred=all_outputs, average='weighted')\n",
        "    recall = recall_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    prec = precision_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    hamming = hamming_score(y_true=all_targets, y_pred=all_outputs)\n",
        "    \n",
        "    f1_scores[\"samples_test\"].append(f1score_samples)\n",
        "    f1_scores[\"macro_test\"].append(f1score_macro)\n",
        "    f1_scores[\"weighted_test\"].append(f1score_weighted)\n",
        "    f1_scores[\"hamming_test\"].append(hamming)\n",
        "    \n",
        "    #Accuracy over entire dataset\n",
        "    test_acc, test_iter, test_loss_val = correct/float(total), count, loss_val/len(test_loader.dataset)\n",
        "    print(\"Test set accuracy: \",test_acc)\n",
        "    print(\"f1_scores\", f1_scores)\n",
        "    train_results['epoch'].append(i)\n",
        "    train_results['train_loss'].append(train_loss_val)\n",
        "    train_results['train_acc'].append(train_acc)\n",
        "    train_results['train_iter'].append(train_iter)\n",
        "    \n",
        "    train_results['test_loss'].append(test_loss_val)\n",
        "    train_results['test_acc'].append(test_acc)\n",
        "    train_results['test_iter'].append(test_iter)\n",
        "    \n",
        "    #Save model with best accuracy\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "fig.savefig('train_curves.png')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0508adf9e6c24f4487b6db98fe11f01c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epochs', max=8.0, style=ProgressStyle(description_width='â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd1c5307dc4b4be5a3fb42a8adb4d48d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Training', max=19.0, style=ProgressStyle(description_widtâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/RecipeNet/datasets/extracted/right_train/150955c319/2e25af00cf.jpg None\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-a8b1267c89d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Running through all mini batches in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#load batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-c8a18c31d486>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HgLjKiPkMLn"
      },
      "source": [
        "#***Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmFAVmC8kRFp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487,
          "referenced_widgets": [
            "6e8216ec492b440b9fb41928a0770f65",
            "c55cc74f5c204699b884ee88a3200ecb",
            "ad55b8ecd4ba4cc1b7f989b44a7cd3e2",
            "72b5a4c17a5f42bf94ab5713db4250e8",
            "39992ba5d1db450191e5694e25bbbdb5",
            "bedca18a35cc4de98169e01fd55d6227",
            "27116289ed7a4fa2ac648f859e0404cc",
            "b5058c5cd6e545cc882b9faf5a260a8b"
          ]
        },
        "outputId": "483783fb-280e-4d0f-d3e5-142832b7228e"
      },
      "source": [
        "#Model switches to test phase\r\n",
        "model.eval()\r\n",
        "\r\n",
        "all_outputs = []\r\n",
        "all_targets = []\r\n",
        "#Running through all mini batches in the dataset\r\n",
        "count, correct, total, lost_val = test_iter, 0, 0, 0\r\n",
        "for img_data, target in tqdm_notebook(test_loader, desc='Testing'):\r\n",
        "    img_data, target = img_data.to(device), target.to(device)\r\n",
        "    output = model(img_data)\r\n",
        "    loss = criterion(output, target) #Cross entropy loss\r\n",
        "    c_loss = loss.data.item()\r\n",
        "    ax3.plot(count, c_loss, 'b.')\r\n",
        "    loss_val += c_loss\r\n",
        "    #Compute accuracy\r\n",
        "    #predicted = output.data.max(1)[1] #get index of max\r\n",
        "    total_batch = (target.size(0) * target.size(1))\r\n",
        "    total += total_batch\r\n",
        "    output_data = torch.sigmoid(output)>=0.5\r\n",
        "    target_data = (target==1.0)\r\n",
        "    #print(\"Predictions: \", output_data)\r\n",
        "    #print(\"Actual: \", target_data)\r\n",
        "    for arr1,arr2 in zip(output_data, target_data):\r\n",
        "        all_outputs.append(list(arr1.cpu().numpy()))\r\n",
        "        all_targets.append(list(arr2.cpu().numpy()))\r\n",
        "    c_acc = torch.sum((output_data == target_data.to(device)).to(torch.float)).item()\r\n",
        "    correct += c_acc\r\n",
        "    count += 1\r\n",
        "#F1 Score\r\n",
        "all_outputs = np.array(all_outputs)\r\n",
        "all_targets = np.array(all_targets)\r\n",
        "f1score_samples = f1_score(y_true=all_targets, y_pred=all_outputs, average='samples')\r\n",
        "f1score_macro = f1_score(y_true=all_targets, y_pred=all_outputs, average='macro')\r\n",
        "f1score_weighted = f1_score(y_true=all_targets, y_pred=all_outputs, average='weighted')\r\n",
        "recall = recall_score(y_true=all_targets, y_pred=all_outputs, average='samples')\r\n",
        "prec = precision_score(y_true=all_targets, y_pred=all_outputs, average='samples')\r\n",
        "hamming = hamming_score(y_true=all_targets, y_pred=all_outputs)\r\n",
        "\r\n",
        "\r\n",
        "print(\"__________________TRAIN RESULTS______________________\")\r\n",
        "print(\"F1_samples\", f1_scores[\"samples_train\"][params[\"epochs\"]])\r\n",
        "print(\"F1_macro\", f1_scores[\"macro_train\"][params[\"epochs\"]])\r\n",
        "print(\"F1_weighted\", f1_scores[\"weighted_train\"][params[\"epochs\"]])\r\n",
        "print(\"Hamming Score\",f1_scores[\"hamming_train\"][params[\"epochs\"]])\r\n",
        "\r\n",
        "print(\"__________________VAL RESULTS______________________\")\r\n",
        "print(\"F1_samples\", f1_scores[\"samples_test\"][params[\"epochs\"]])\r\n",
        "print(\"F1_macro\", f1_scores[\"macro_test\"][params[\"epochs\"]])\r\n",
        "print(\"F1_weighted\", f1_scores[\"weighted_test\"][params[\"epochs\"]])\r\n",
        "print(\"Hamming Score\",f1_scores[\"hamming_test\"][params[\"epochs\"]])\r\n",
        "\r\n",
        "\r\n",
        "print(\"__________________TEST RESULTS______________________\")\r\n",
        "print(\"F1_samples\", f1score_samples)\r\n",
        "print(\"F1_macro\", f1score_macro)\r\n",
        "print(\"F1_weighted\", f1score_weighted)\r\n",
        "print(\"Recall\",recall)\r\n",
        "print(\"Precision\",prec)\r\n",
        "print(\"Hamming Score\",hamming)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e8216ec492b440b9fb41928a0770f65",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Testing', max=19.0, style=ProgressStyle(description_widthâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "__________________TRAIN RESULTS______________________\n",
            "F1_samples 0.9987777777777778\n",
            "F1_macro 0.05718569677804612\n",
            "F1_weighted 0.9987670527807312\n",
            "Hamming Score 0.9985897435897436\n",
            "__________________VAL RESULTS______________________\n",
            "F1_samples 0.293266716832932\n",
            "F1_macro 0.024882617241039597\n",
            "F1_weighted 0.17056219622876548\n",
            "Hamming Score 0.2253568685828201\n",
            "__________________TEST RESULTS______________________\n",
            "F1_samples 0.5689205653021442\n",
            "F1_macro 0.04078754060005157\n",
            "F1_weighted 0.42822003043096835\n",
            "Recall 0.5596078042328042\n",
            "Precision 0.582125\n",
            "Hamming Score 0.5098944978632479\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkqrTDYGCm-8",
        "outputId": "384b6f92-2123-4661-84a2-afb2b1d11092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "import shutil\r\n",
        "f5 = open('/content/drive/MyDrive/RecipeNet/datasets/extracted/layer1_final_img.json',)\r\n",
        "layer1_final_img = json.load(f5)\r\n",
        "\r\n",
        "sorted_layer = sorted(layer1_final_img, key=lambda k: k['title']) \r\n",
        "\r\n",
        "for elem in sorted_layer:\r\n",
        "  elem['title'] = elem['title'].replace(' ','_')\r\n",
        "\r\n",
        "path1 = \"/content/drive/MyDrive/RecipeNet/datasets/extracted/right_train\"\r\n",
        "dst = \"/content/drive/MyDrive/RecipeNet/datasets/extracted/new_right_train\"\r\n",
        "\r\n",
        "for root, dirs, files in os.walk(dst):\r\n",
        "  for elem in sorted_layer:\r\n",
        "    if os.path.basename(root) == elem['title']:\r\n",
        "      destination = os.path.realpath(root)\r\n",
        "      for img in elem['images']:\r\n",
        "        origin = path1 + '/' + img['id']\r\n",
        "        shutil.copy(origin, destination)\r\n",
        "      print(destination, ' copied!')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-20ba09f4652d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0morigin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' copied!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: '/content/drive/MyDrive/RecipeNet/datasets/extracted/right_train/00fd89986e.jpg'"
          ]
        }
      ]
    }
  ]
}