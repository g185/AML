{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AML_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UXG6e2PquoqN",
        "unyTDi0vbuRC",
        "3iZSnFTLNDim",
        "YgMUIGbwwtHO",
        "H4eBCcS-wmKI",
        "oF8XFzrUwwXz"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/g185/AMLrepository/blob/main/RecipeNet/AML_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mKzPUY-32Av"
      },
      "source": [
        "**To Do**\r\n",
        "\r\n",
        "*   Add Params in order to start make the two datasets parametric\r\n",
        "(Project Parameters + Data extraction & preprocessing)\r\n",
        "*   Loading Function\r\n",
        "(Training + Loading)\r\n",
        "*   Example\r\n",
        "(Example)\r\n",
        "*   Add information about size of dataset in parameters\r\n",
        "(Projexct Parameters)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXG6e2PquoqN"
      },
      "source": [
        "#***Download and unzip Dataset***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhlPBhD98p94"
      },
      "source": [
        "*   Create folders\n",
        "*   Download Recipe 5K + Annotations in drive\n",
        "*   Unzip files in folder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUrWflPRudbx"
      },
      "source": [
        "#Create folders for models and datasets\n",
        "!mkdir \"/content/drive/My Drive/RecipeNet\" \n",
        "!mkdir \"/content/drive/My Drive/RecipeNet/datasets\" \n",
        "!mkdir \"/content/drive/My Drive/RecipeNet/datasets/download\" \n",
        "!mkdir \"/content/drive/My Drive/RecipeNet/datasets/extracted\" \n",
        "!mkdir \"/content/drive/My Drive/RecipeNet/datasets/preprocessed\" \n",
        "!mkdir \"/content/drive/My Drive/RecipeNet/model\" \n",
        "#Scarica dataset\n",
        "#Trascina i 3 zip\n",
        "\n",
        "#Unzip\n",
        "\"\"\"\n",
        "!unzip \"/content/drive/My Drive/RecipeNet/datasets/download/new_right_train.zip\" -d \"/content/drive/My Drive/RecipeNet_g/datasets/extracted\"\n",
        "!unzip \"/content/drive/My Drive/RecipeNet/datasets/download/archive.zip\" -d \"/content/drive/My Drive/RecipeNet/datasets/extracted\"\n",
        "!unzip \"/content/drive/My Drive/RecipeNet/datasets/download/Ingredients101.zip\" -d \"/content/drive/My Drive/RecipeNet/datasets/extracted\"\n",
        "\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT-TwMVuBLEv"
      },
      "source": [
        "#***Imports and Drive Mount***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOJPDp-bU6rr"
      },
      "source": [
        "#Imports\n",
        "import sys\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from tqdm.notebook import tqdm, trange\n",
        "import sys\n",
        "import cv2\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from glob import glob\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "#Cuda\n",
        "device = torch.device(\"cuda\")\n",
        "torch.manual_seed(42) # try and make the results more reproducible\n",
        "print(torch.cuda.get_device_name(0))\n",
        "\n",
        "#Drive Mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_AXoIoMB0om"
      },
      "source": [
        "#***Project Parameters***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYIvhj8aB4NV"
      },
      "source": [
        "params = {}\n",
        "\n",
        "#DATASET KEYWORD\n",
        "params[\"dataset\"] = \"Recipe5k\"\n",
        "\n",
        "#NEURAL NETWORK PARAMS\n",
        "params[\"freezed_layers\"] = 8\n",
        "\n",
        "#GENERAL TRAINING PARAMS\n",
        "params[\"epochs\"] = 20\n",
        "params[\"batch_size\"] = 64\n",
        "params[\"img_size\"] = (384,384)\n",
        "\n",
        "#FAST TRAINING SETTINGS\n",
        "#1M: TR:67000 VAL:5400 TE:27000\n",
        "#5k: TR: VAL: TE:\n",
        "params[\"fast_training\"] = True\n",
        "params[\"train_df_size\"] = 120\n",
        "params[\"val_df_size\"] = 120\n",
        "params[\"test_df_size\"] = 120\n",
        "\n",
        "\n",
        "#DATASET SETTINGS\n",
        "params[\"root\"] = \"/content/drive/My Drive/RecipeNet/\"\n",
        "if params[\"dataset\"] == \"Recipe5k\":\n",
        "    params[\"images_dir\"] = params[\"root\"] + \"datasets/extracted/images/\" \n",
        "    params[\"ingredients_per_class\"] = params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/ingredients_simplified.txt\" \n",
        "    params[\"classes\"] = params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/classes.txt\" \n",
        "    params[\"baseIngredients_dir\"] = params[\"root\"] + \"datasets/extracted/Ingredients101/ingredients_simplification/baseIngredients.txt\" \n",
        "    params[\"annotations_path\"] = params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/\"\n",
        "elif params[\"dataset\"] == \"Recipe1M\":\n",
        "    params[\"images_dir\"] = params[\"root\"] + \"datasets/extracted/new_right_train/\" \n",
        "    params[\"annotations_path\"] = params[\"root\"] + \"datasets/extracted/Annotations_1M/\"\n",
        "    params[\"ingredients_per_class\"] = params[\"root\"] + \"datasets/extracted/Annotations_1M/ingr.txt\" \n",
        "    params[\"classes\"] = params[\"root\"] + \"datasets/extracted/Annotations_1M/newclasses.txt\" \n",
        "    params[\"baseIngredients_dir\"] = params[\"root\"] + \"datasets/extracted/Annotations_1M/baseIngredients.txt\" \n",
        "    params[\"annotations_path\"] = params[\"root\"] + \"datasets/extracted/Annotations_1M/\"\n",
        "else:\n",
        "    print(\"Invalid Dataset Keyword, try with Recipe1M or Recipe5k\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzkRmamqNDt_"
      },
      "source": [
        "#***Data extraction and preprocessing***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5tPzq9WjV77"
      },
      "source": [
        "Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBw5OIEM8Gw5"
      },
      "source": [
        "#Ingredients x class\r\n",
        "f = open(params[\"ingredients_per_class\"], \"r\")\r\n",
        "ingredients = f.read().split('\\n')\r\n",
        "f.close()\r\n",
        "\r\n",
        "#Classes\r\n",
        "f = open(params[\"classes\"], \"r\")\r\n",
        "classes = f.read().split('\\n')\r\n",
        "f.close()\r\n",
        "\r\n",
        "#Ingredients\r\n",
        "f = open(params[\"baseIngredients_dir\"], \"r\")\r\n",
        "base_ing = f.read().split('\\n')\r\n",
        "base_ing = base_ing[0].split(\",\")\r\n",
        "f.close()\r\n",
        "\r\n",
        "#train images\r\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/train_images.txt\", \"r\")\r\n",
        "train_images = f.read().split('\\n')\r\n",
        "f.close()\r\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/train_labels.txt\", \"r\")\r\n",
        "train_labels = f.read().split('\\n')\r\n",
        "f.close()\r\n",
        "\r\n",
        "#validation images\r\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/val_images.txt\", \"r\")\r\n",
        "val_images = f.read().split('\\n')\r\n",
        "f.close()\r\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/val_labels.txt\", \"r\")\r\n",
        "val_labels = f.read().split('\\n')\r\n",
        "f.close()\r\n",
        "\r\n",
        "#test images\r\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/test_images.txt\", \"r\")\r\n",
        "test_images = f.read().split('\\n')\r\n",
        "f.close()\r\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Ingredients101/Annotations/test_labels.txt\", \"r\")\r\n",
        "test_labels = f.read().split('\\n')\r\n",
        "f.close()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtUqblzXja33"
      },
      "source": [
        "#Ingredients x class\n",
        "f = open(params[\"ingredients_per_class\"], \"r\")\n",
        "ingredients = f.read().split('\\n')\n",
        "f.close()\n",
        "\n",
        "#Classes\n",
        "f = open(params[\"classes\"], \"r\")\n",
        "classes = f.read().split('\\n')\n",
        "f.close()\n",
        "\n",
        "#Ingredients\n",
        "f = open(params[\"baseIngredients_dir\"], \"r\")\n",
        "base_ing = f.read().split('\\n')\n",
        "base_ing = base_ing[0].split(\",\")\n",
        "f.close()\n",
        "\n",
        "#train images\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Annotations_1M/train_imgs.txt\", \"r\")\n",
        "train_images = f.read().split('\\n')\n",
        "f.close()\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Annotations_1M/train_lab.txt\", \"r\")\n",
        "train_labels = f.read().split('\\n')\n",
        "f.close()\n",
        "\n",
        "#validation images\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Annotations_1M/val_imgs.txt\", \"r\")\n",
        "val_images = f.read().split('\\n')\n",
        "f.close()\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Annotations_1M/val_lab.txt\", \"r\")\n",
        "val_labels = f.read().split('\\n')\n",
        "f.close()\n",
        "\n",
        "#test images\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Annotations_1M/test_imgs.txt\", \"r\")\n",
        "test_images = f.read().split('\\n')\n",
        "f.close()\n",
        "f = open(params[\"root\"] + \"datasets/extracted/Annotations_1M/test_lab.txt\", \"r\")\n",
        "test_labels = f.read().split('\\n')\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URPn4rnyjjoj"
      },
      "source": [
        "Dataframes Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOoX41Sdjm3A"
      },
      "source": [
        "#list of string in list of list of tokens\n",
        "new_ingredients = [arr.split(\",\") for arr in ingredients]\n",
        "\n",
        "#binary encode ingredients\n",
        "mlb = MultiLabelBinarizer()\n",
        "df = pd.DataFrame(mlb.fit_transform(new_ingredients),columns=mlb.classes_) \n",
        "df[\"target\"] = classes\n",
        "food_dict = df\n",
        "train_images = [params[\"images_dir\"] + s + \".jpg\" for s in train_images]\n",
        "all_img_df = pd.DataFrame({'path': train_images, 'class_id': train_labels})\n",
        "val_images = [params[\"images_dir\"] + s + \".jpg\" for s in val_images]\n",
        "val_img_df = pd.DataFrame({'path': val_images, 'class_id': val_labels})\n",
        "test_images = [params[\"images_dir\"] + s + \".jpg\" for s in test_images]\n",
        "test_img_df = pd.DataFrame({'path': test_images, 'class_id': test_labels})\n",
        "all_img_df = all_img_df[:-1]\n",
        "val_img_df = val_img_df[:-1]\n",
        "test_img_df = test_img_df[:-1]\n",
        "\n",
        "\n",
        "\n",
        "all_img_df['class_name'] = all_img_df['path'].map(lambda x: os.path.split(os.path.dirname(x))[-1])\n",
        "val_img_df['class_name'] = val_img_df['path'].map(lambda x: os.path.split(os.path.dirname(x))[-1])\n",
        "test_img_df['class_name'] = test_img_df['path'].map(lambda x: os.path.split(os.path.dirname(x))[-1])\n",
        "\n",
        "#food_dict = food_dict.drop('', 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "468oZbcTjzjI"
      },
      "source": [
        "Train Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su9RKGPwj3M7"
      },
      "source": [
        "#Dataframe for train images\n",
        "new_data = []\n",
        "for index, row in all_img_df.iterrows():\n",
        "    #get binary encoding ingredients from lookup\n",
        "    food = row[\"class_name\"]\n",
        "    path = row[\"path\"]\n",
        "    class_id = row[\"class_id\"]\n",
        "    binary_encod = food_dict.loc[food_dict[\"target\"] == food]\n",
        "    binary_encod[\"path\"] = path\n",
        "    binary_encod[\"class_id\"] = class_id\n",
        "    #print(binary_encod[\"class_id\"])\n",
        "    #print((list(binary_encod.columns.values)))\n",
        "    #print(len(np.array(binary_encod)[0]))\n",
        "    new_data.append(np.array(binary_encod)[0])\n",
        "\n",
        "\n",
        "\n",
        "col_names = list(binary_encod.columns.values)\n",
        "print(len(col_names))\n",
        "train_df = pd.DataFrame(new_data, columns = col_names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTtejOUlj4l2"
      },
      "source": [
        "Validation Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE5pj15Ij75W"
      },
      "source": [
        "val_data = []\n",
        "for index, row in val_img_df.iterrows():\n",
        "    #get binary encoding ingredients from lookup\n",
        "    food = row[\"class_name\"]\n",
        "    path = row[\"path\"]\n",
        "    class_id = row[\"class_id\"]\n",
        "    binary_encod = food_dict.loc[food_dict[\"target\"] == food]\n",
        "    binary_encod[\"path\"] = path\n",
        "    binary_encod[\"class_id\"] = int(class_id)\n",
        "    val_data.append(np.array(binary_encod)[0])\n",
        "val_df = pd.DataFrame(val_data, columns = col_names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHK2_X4fj-l_"
      },
      "source": [
        "Test Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzdWTpbZeyap"
      },
      "source": [
        "test_data = []\n",
        "for index, row in test_img_df.iterrows():\n",
        "    #get binary encoding ingredients from lookup\n",
        "    food = row[\"class_name\"]\n",
        "    path = row[\"path\"]\n",
        "    class_id = row[\"class_id\"]\n",
        "    binary_encod = food_dict.loc[food_dict[\"target\"] == food]\n",
        "    binary_encod[\"path\"] = path\n",
        "    binary_encod[\"class_id\"] = int(class_id)\n",
        "    test_data.append(np.array(binary_encod)[0])\n",
        "\n",
        "\n",
        "test_df = pd.DataFrame(test_data, columns = col_names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unyTDi0vbuRC"
      },
      "source": [
        "#***DataGenerator***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CtfDNypczIt"
      },
      "source": [
        "class DataWrapper(data.Dataset):\n",
        "    ''' Data wrapper for pytorch's data loader function '''\n",
        "    def __init__(self, image_df, resize):\n",
        "        self.dataset = image_df\n",
        "        self.resize = resize\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        c_row = self.dataset.iloc[index]\n",
        "        target_arr = []\n",
        "        for item in c_row[targets].values:\n",
        "            target_arr.append(item)\n",
        "        #print(target_arr)\n",
        "        image_path, target = c_row['path'], torch.from_numpy(np.array(target_arr)).float()  #image and target\n",
        "        #read as rgb image, resize and convert to range 0 to 1\n",
        "        image = cv2.imread(image_path, 1)\n",
        "        #print(image_path, image)\n",
        "        if self.resize:\n",
        "            image = cv2.resize(image, params[\"img_size\"])/255.0 \n",
        "        else:\n",
        "            image = image/255.0\n",
        "        image = (torch.from_numpy(image.transpose(2,0,1))).float() #NxCxHxW\n",
        "        return image, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iZSnFTLNDim"
      },
      "source": [
        "#***Trasfer Learning Model:ResNet***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bWUNYL4wdKR"
      },
      "source": [
        "col_names = list(train_df.columns.values)\n",
        "targets = col_names[:-3]\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "output = len(targets)\n",
        "model.fc = nn.Linear(model.fc.in_features, output)\n",
        "\n",
        "layer = 0\n",
        "for name, child in model.named_children():\n",
        "    layer += 1\n",
        "    if layer < params[\"freezed_layers\"]:\n",
        "        for name2, param in child.named_parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgMUIGbwwtHO"
      },
      "source": [
        "#***Training***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tejkwYHPhx5o"
      },
      "source": [
        "Define Hamming Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1l7jgF4h83W"
      },
      "source": [
        "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
        "    '''\n",
        "    Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
        "    https://stackoverflow.com/q/32239577/395857\n",
        "    '''\n",
        "    acc_list = []\n",
        "    for i in range(y_true.shape[0]):\n",
        "        set_true = set( np.where(y_true[i])[0] )\n",
        "        set_pred = set( np.where(y_pred[i])[0] )\n",
        "        tmp_a = None\n",
        "        if len(set_true) == 0 and len(set_pred) == 0:\n",
        "            tmp_a = 1\n",
        "        else:\n",
        "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
        "                    float( len(set_true.union(set_pred)) )\n",
        "        acc_list.append(tmp_a)\n",
        "    return np.mean(acc_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5P5t3kOiWyN"
      },
      "source": [
        "Training Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAGn6B-hiZlR"
      },
      "source": [
        "if params[\"fast_training\"] == True:\n",
        "    train_df = train_df[:params[\"train_df_size\"]]\n",
        "    val_df = val_df[:params[\"val_df_size\"]]\n",
        "    test_df = test_df[:params[\"test_df_size\"]]\n",
        "            \n",
        "print(len(val_df))\n",
        "model = model.to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4BOAUZSif36"
      },
      "source": [
        "Dataset Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN34WEC3iiLB"
      },
      "source": [
        "train_dataset = DataWrapper(train_df, True)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,shuffle=True, batch_size=params[\"batch_size\"], pin_memory=False)\n",
        "\n",
        "val_dataset = DataWrapper(val_df, True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset,shuffle=True, batch_size=params[\"batch_size\"], pin_memory=False)\n",
        "\n",
        "test_dataset = DataWrapper(test_df, True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,shuffle=True, batch_size=params[\"batch_size\"], pin_memory=False)\n",
        "\n",
        "#Definisco i plots\n",
        "train_results = defaultdict(list)\n",
        "train_iter, test_iter, best_acc = 0,0,0\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize = (10, 10))\n",
        "ax1.set_title('Train Loss')\n",
        "ax2.set_title('Train Accuracy')\n",
        "ax3.set_title('Test Loss')\n",
        "ax4.set_title('Test Accuracy')\n",
        "\n",
        "#dizionario f1 scores\n",
        "f1_scores = defaultdict(list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCjVOOL4i48a"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THX6oDqxqblX"
      },
      "source": [
        "\n",
        "for i in trange(params[\"epochs\"], desc='Epochs'):\n",
        "    print(\"Epoch \",i)\n",
        "    ## Train Phase\n",
        "    #Model switches to train phase\n",
        "    model.train() \n",
        "    \n",
        "    #azzera ris\n",
        "    all_outputs = []\n",
        "    all_targets = []\n",
        "\n",
        "    # Running through all mini batches in the dataset\n",
        "    count, loss_val, correct, total = train_iter, 0, 0, 0\n",
        "    for img_data, target in tqdm(train_loader, desc='Training'):  \n",
        "\n",
        "        #load batch  \n",
        "        img_data, target = img_data.to(device), target.to(device)\n",
        "        #FWD prop\n",
        "        output = model(img_data) \n",
        "\n",
        "        #Cross entropy loss\n",
        "        loss = criterion(output, target) \n",
        "\n",
        "        #current loss \n",
        "        c_loss = loss.data.item()\n",
        "\n",
        "        #plot current loss\n",
        "        ax1.plot(count, c_loss, 'r.')\n",
        "\n",
        "        #accumulate loss for training phase\n",
        "        loss_val += c_loss\n",
        "\n",
        "        optimizer.zero_grad() #Zero out any cached gradients\n",
        "        loss.backward() #Backward pass\n",
        "        optimizer.step() #Update the weights\n",
        "\n",
        "        #number of outputs, batch * labels\n",
        "        total_batch = (target.size(0) * target.size(1))\n",
        "        total += total_batch\n",
        "\n",
        "        #output and targets\n",
        "        output_data = torch.sigmoid(output)>=0.5\n",
        "        target_data = (target==1.0)\n",
        "        \n",
        "        #carica i risultati e i target\n",
        "        for arr1,arr2 in zip(output_data, target_data):\n",
        "            all_outputs.append(list(arr1.cpu().numpy()))\n",
        "            all_targets.append(list(arr2.cpu().numpy()))\n",
        "\n",
        "        #accuracy\n",
        "        c_acc = torch.sum((output_data == target_data.to(device)).to(torch.float)).item()\n",
        "        \n",
        "        #plot accuracy\n",
        "        ax2.plot(count, c_acc/total_batch, 'r.')\n",
        "\n",
        "        #accumula accuracy\n",
        "        correct += c_acc\n",
        "\n",
        "        #accumula numero di steps per epoch\n",
        "        count +=1\n",
        "        \n",
        "    #prendi i risultati dell'ultimo training\n",
        "    all_outputs = np.array(all_outputs)\n",
        "    all_targets = np.array(all_targets)\n",
        "\n",
        "    #Training Metrics\n",
        "    #______________________________________________________________________________________________________\n",
        "    f1score_samples = f1_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    f1score_macro = f1_score(y_true=all_targets, y_pred=all_outputs, average='macro')\n",
        "    f1score_weighted = f1_score(y_true=all_targets, y_pred=all_outputs, average='weighted')\n",
        "    recall = recall_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    prec = precision_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    hamming = hamming_score(y_true=all_targets, y_pred=all_outputs)\n",
        "    \n",
        "    f1_scores[\"samples_train\"].append(f1score_samples)\n",
        "    f1_scores[\"macro_train\"].append(f1score_macro)\n",
        "    f1_scores[\"weighted_train\"].append(f1score_weighted)\n",
        "    f1_scores[\"hamming_train\"].append(hamming)\n",
        "    #____________________________________________________________________________________________________________________\n",
        "    #Training loss val è loss per image,\n",
        "    #train_iter è count, numero di steps, images in training / batch size * epoch number\n",
        "    #train_acc over training\n",
        "    train_loss_val, train_iter, train_acc = loss_val/len(train_loader.dataset), count, correct/float(total)\n",
        "    \n",
        "    print(\"Training loss: \", train_loss_val, \" train acc: \",train_acc)    \n",
        "    ## Test Phase\n",
        "    \n",
        "    #Model switches to test phase\n",
        "    model.eval()\n",
        "    \n",
        "    all_outputs = []\n",
        "    all_targets = []\n",
        "    #Running through all mini batches in the dataset\n",
        "    count, correct, total, lost_val = test_iter, 0, 0, 0\n",
        "    for img_data, target in tqdm(val_loader, desc='Validation'):\n",
        "        img_data, target = img_data.to(device), target.to(device)\n",
        "        print(img_data.size())\n",
        "        output = model(img_data)\n",
        "        loss = criterion(output, target) #Cross entropy loss\n",
        "        c_loss = loss.data.item()\n",
        "        ax3.plot(count, c_loss, 'b.')\n",
        "        loss_val += c_loss\n",
        "        #Compute accuracy\n",
        "        #predicted = output.data.max(1)[1] #get index of max\n",
        "        total_batch = (target.size(0) * target.size(1))\n",
        "        total += total_batch\n",
        "        output_data = torch.sigmoid(output)>=0.5\n",
        "        target_data = (target==1.0)\n",
        "        #print(\"Predictions: \", output_data)\n",
        "        #print(\"Actual: \", target_data)\n",
        "        for arr1,arr2 in zip(output_data, target_data):\n",
        "            all_outputs.append(list(arr1.cpu().numpy()))\n",
        "            all_targets.append(list(arr2.cpu().numpy()))\n",
        "        c_acc = torch.sum((output_data == target_data.to(device)).to(torch.float)).item()\n",
        "        ax4.plot(count, c_acc/total_batch, 'b.')\n",
        "        correct += c_acc\n",
        "        count += 1\n",
        "    \n",
        "    #print(\"Outputs: \", len(all_outputs), \" x \", len(all_outputs[0]))\n",
        "    #print(\"Targets: \", len(all_targets), \" x \", len(all_targets[0]))\n",
        "    \n",
        "    #F1 Score\n",
        "    all_outputs = np.array(all_outputs)\n",
        "    all_targets = np.array(all_targets)\n",
        "    f1score_samples = f1_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    f1score_macro = f1_score(y_true=all_targets, y_pred=all_outputs, average='macro')\n",
        "    f1score_weighted = f1_score(y_true=all_targets, y_pred=all_outputs, average='weighted')\n",
        "    recall = recall_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    prec = precision_score(y_true=all_targets, y_pred=all_outputs, average='samples')\n",
        "    hamming = hamming_score(y_true=all_targets, y_pred=all_outputs)\n",
        "    \n",
        "    f1_scores[\"samples_test\"].append(f1score_samples)\n",
        "    f1_scores[\"macro_test\"].append(f1score_macro)\n",
        "    f1_scores[\"weighted_test\"].append(f1score_weighted)\n",
        "    f1_scores[\"hamming_test\"].append(hamming)\n",
        "    \n",
        "    #Accuracy over entire dataset\n",
        "    test_acc, test_iter, test_loss_val = correct/float(total), count, loss_val/len(test_loader.dataset)\n",
        "    print(\"Test set accuracy: \",test_acc)\n",
        "    print(\"f1_scores\", f1_scores)\n",
        "    train_results['epoch'].append(i)\n",
        "    train_results['train_loss'].append(train_loss_val)\n",
        "    train_results['train_acc'].append(train_acc)\n",
        "    train_results['train_iter'].append(train_iter)\n",
        "    \n",
        "    train_results['test_loss'].append(test_loss_val)\n",
        "    train_results['test_acc'].append(test_acc)\n",
        "    train_results['test_iter'].append(test_iter)\n",
        "    \n",
        "    #Save model with best accuracy\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "fig.savefig('train_curves.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4eBCcS-wmKI"
      },
      "source": [
        "#***Save***\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0_SQkFKsm57"
      },
      "source": [
        "model_name = \"test_recipe1m_13400_20_epochs\"\r\n",
        "\r\n",
        "\r\n",
        "PATH = \"/content/drive/My Drive/RecipeNet/model/\"+ model_name + \".pt\"\r\n",
        "\r\n",
        "torch.save({\r\n",
        "            'epoch': params[\"epochs\"],\r\n",
        "            'model_state_dict': model.state_dict(),\r\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\r\n",
        "            'f1_scores': f1_scores,\r\n",
        "            'train_results': train_results \r\n",
        "            }, PATH)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF8XFzrUwwXz"
      },
      "source": [
        "#***Load***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JSOlq7LuA0O"
      },
      "source": [
        "model_name = \"test_recipe1m_13400_images_10_epochs\"\r\n",
        "model_name = \"resnet_model_half_dataset\"\r\n",
        "\r\n",
        "#Definisco i plots\r\n",
        "train_results = defaultdict(list)\r\n",
        "train_iter, test_iter, best_acc = 0,0,0\r\n",
        "\r\n",
        "#dizionario f1 scores\r\n",
        "f1_scores = defaultdict(list)\r\n",
        "\r\n",
        "PATH = \"/content/drive/My Drive/RecipeNet/model/\"+model_name+\".pt\"\r\n",
        "checkpoint = torch.load(PATH)\r\n",
        "\r\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\r\n",
        "\r\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\r\n",
        "\r\n",
        "epoch = checkpoint['epoch']\r\n",
        "\r\n",
        "f1_scores = checkpoint['f1_scores']\r\n",
        "\r\n",
        "train_results = checkpoint['train_results']\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HgLjKiPkMLn"
      },
      "source": [
        "#***Evaluation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmFAVmC8kRFp"
      },
      "source": [
        "#Model switches to test phase\r\n",
        "model.eval()\r\n",
        "\"\"\"\r\n",
        "all_outputs = []\r\n",
        "all_targets = []\r\n",
        "#Running through all mini batches in the dataset\r\n",
        "count, correct, total, lost_val = test_iter, 0, 0, 0\r\n",
        "for img_data, target in tqdm(test_loader, desc='Testing'):\r\n",
        "    img_data, target = img_data.to(device), target.to(device)\r\n",
        "    output = model(img_data)\r\n",
        "    loss = criterion(output, target) #Cross entropy loss\r\n",
        "    c_loss = loss.data.item()\r\n",
        "    ax3.plot(count, c_loss, 'b.')\r\n",
        "    loss_val += c_loss\r\n",
        "    #Compute accuracy\r\n",
        "    #predicted = output.data.max(1)[1] #get index of max\r\n",
        "    total_batch = (target.size(0) * target.size(1))\r\n",
        "    total += total_batch\r\n",
        "    output_data = torch.sigmoid(output)>=0.5\r\n",
        "    target_data = (target==1.0)\r\n",
        "    #print(\"Predictions: \", output_data)\r\n",
        "    #print(\"Actual: \", target_data)\r\n",
        "    for arr1,arr2 in zip(output_data, target_data):\r\n",
        "        all_outputs.append(list(arr1.cpu().numpy()))\r\n",
        "        all_targets.append(list(arr2.cpu().numpy()))\r\n",
        "    c_acc = torch.sum((output_data == target_data.to(device)).to(torch.float)).item()\r\n",
        "    correct += c_acc\r\n",
        "    count += 1\r\n",
        "\"\"\"\r\n",
        "#F1 Score\r\n",
        "all_outputs = np.array(all_outputs)\r\n",
        "all_targets = np.array(all_targets)\r\n",
        "f1score_samples = f1_score(y_true=all_targets, y_pred=all_outputs, average='samples')\r\n",
        "f1score_macro = f1_score(y_true=all_targets, y_pred=all_outputs, average='macro')\r\n",
        "f1score_weighted = f1_score(y_true=all_targets, y_pred=all_outputs, average='weighted')\r\n",
        "recall = recall_score(y_true=all_targets, y_pred=all_outputs, average='samples')\r\n",
        "prec = precision_score(y_true=all_targets, y_pred=all_outputs, average='samples')\r\n",
        "\r\n",
        "hamming = hamming_score(y_true=all_targets, y_pred=all_outputs)\r\n",
        "\r\n",
        "params[\"epochs\"] = 19\r\n",
        "print(\"__________________TRAIN RESULTS______________________\")\r\n",
        "print(\"F1_samples\", f1_scores[\"samples_train\"][params[\"epochs\"]])\r\n",
        "print(\"F1_macro\", f1_scores[\"macro_train\"][params[\"epochs\"]])\r\n",
        "print(\"F1_weighted\", f1_scores[\"weighted_train\"][params[\"epochs\"]])\r\n",
        "print(\"Hamming Score\",f1_scores[\"hamming_train\"][params[\"epochs\"]])\r\n",
        "\r\n",
        "print(\"__________________VAL RESULTS______________________\")\r\n",
        "print(\"F1_samples\", f1_scores[\"samples_test\"][params[\"epochs\"]])\r\n",
        "print(\"F1_macro\", f1_scores[\"macro_test\"][params[\"epochs\"]])\r\n",
        "print(\"F1_weighted\", f1_scores[\"weighted_test\"][params[\"epochs\"]])\r\n",
        "print(\"Hamming Score\",f1_scores[\"hamming_test\"][params[\"epochs\"]])\r\n",
        "\r\n",
        "\r\n",
        "print(\"__________________TEST RESULTS______________________\")\r\n",
        "print(\"F1_samples\", f1score_samples)\r\n",
        "print(\"F1_macro\", f1score_macro)\r\n",
        "print(\"F1_weighted\", f1score_weighted)\r\n",
        "print(\"Recall\",recall)\r\n",
        "print(\"Precision\",prec)\r\n",
        "print(\"Hamming Score\",hamming)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gvbw-eX6jxw"
      },
      "source": [
        "image_path = \"/content/drive/My Drive/RecipeNet/pizza.jpg\"\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "#read as rgb image, resize and convert to range 0 to 1\r\n",
        "image = cv2.imread(image_path, 1)\r\n",
        "image = cv2.resize(image, params[\"img_size\"])/255\r\n",
        "\r\n",
        "print(len(new_ingredients), len(food_dict), len(col_names))\r\n",
        "image = (torch.from_numpy(image.transpose(2,0,1))).float() \r\n",
        "image = image.unsqueeze(0)\r\n",
        "image = image.to(device)\r\n",
        "\r\n",
        "output = model(image) \r\n",
        "\r\n",
        "output_data = torch.sigmoid(output)>=0.5\r\n",
        "\"\"\"\r\n",
        "print(output_data)\r\n",
        "print(\"output\", len(output_data.cpu().numpy()[0]))\r\n",
        "print(\"ingredients\",len(col_names))\r\n",
        "print(col_names)\"\"\"\r\n",
        "\r\n",
        "for i, elem in enumerate(output_data.cpu().numpy()[0]):\r\n",
        "    if elem:\r\n",
        "        print(col_names[i])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}